<!doctype html>
<html lang="id" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-5-planning-memory-decision/chapter-3" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Context Management and Retrieval | Learning Materials</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://localhost:3000/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="http://localhost:3000/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="http://localhost:3000/module-5-planning-memory-decision/chapter-3"><meta data-rh="true" property="og:locale" content="id"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="id"><meta data-rh="true" name="docsearch:language" content="id"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Context Management and Retrieval | Learning Materials"><meta data-rh="true" name="description" content="Learning Objectives"><meta data-rh="true" property="og:description" content="Learning Objectives"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="http://localhost:3000/module-5-planning-memory-decision/chapter-3"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-5-planning-memory-decision/chapter-3" hreflang="id"><link data-rh="true" rel="alternate" href="http://localhost:3000/en/module-5-planning-memory-decision/chapter-3" hreflang="en"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-5-planning-memory-decision/chapter-3" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Context Management and Retrieval","item":"http://localhost:3000/module-5-planning-memory-decision/chapter-3"}]}</script><link rel="stylesheet" href="/assets/css/styles.b3bb77c0.css">
<script src="/assets/js/runtime~main.ea5f7858.js" defer="defer"></script>
<script src="/assets/js/main.e790a99d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Lewati ke konten utama"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Lewati ke konten utama</a></div><nav aria-label="Utama" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alihkan bilah sisi" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Learning Materials</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Bahasa Indonesia</a><ul class="dropdown__menu"><li><a href="/module-5-planning-memory-decision/chapter-3" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="id">Bahasa Indonesia</a></li><li><a href="/en/module-5-planning-memory-decision/chapter-3" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Ubah antara modus gelap dan modus terang (saat ini system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Gulir kembali ke atas" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Bilah sisi dokumentasi" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/"><span title="Deep Dive into Agentic AI: Design, Implementation, and Production Systems" class="linkLabel_WmDU">Deep Dive into Agentic AI: Design, Implementation, and Production Systems</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-1-introduction-agentic-ai/chapter-1"><span title="Introduction to Agentic AI and Autonomous Systems" class="categoryLinkLabel_W154">Introduction to Agentic AI and Autonomous Systems</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-2-core-components/chapter-1"><span title="Core Components of an AI Agent" class="categoryLinkLabel_W154">Core Components of an AI Agent</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-3-architectures-patterns/chapter-1"><span title="Agent Architectures and Design Patterns" class="categoryLinkLabel_W154">Agent Architectures and Design Patterns</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-4-agent-frameworks/chapter-1"><span title="Building Agents with Modern Frameworks" class="categoryLinkLabel_W154">Building Agents with Modern Frameworks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/module-5-planning-memory-decision/chapter-1"><span title="Planning, Memory, and Decision-Making" class="categoryLinkLabel_W154">Planning, Memory, and Decision-Making</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/module-5-planning-memory-decision/chapter-1"><span title="Task Decomposition and Planning Strategies" class="linkLabel_WmDU">Task Decomposition and Planning Strategies</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/module-5-planning-memory-decision/chapter-2"><span title="Vector Databases and Long-Term Memory" class="linkLabel_WmDU">Vector Databases and Long-Term Memory</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/module-5-planning-memory-decision/chapter-3"><span title="Context Management and Retrieval" class="linkLabel_WmDU">Context Management and Retrieval</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/module-5-planning-memory-decision/chapter-4"><span title="Decision-Making Under Uncertainty" class="linkLabel_WmDU">Decision-Making Under Uncertainty</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-6-multi-agent/chapter-1"><span title="Multi-Agent Systems and Collaboration" class="categoryLinkLabel_W154">Multi-Agent Systems and Collaboration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-7-evaluation-safety/chapter-1"><span title="Evaluation, Safety, and Alignment" class="categoryLinkLabel_W154">Evaluation, Safety, and Alignment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-8-scaling-production/chapter-1"><span title="Scaling, Optimization, and Production Deployment" class="categoryLinkLabel_W154">Scaling, Optimization, and Production Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-9-capstone/chapter-1"><span title="Capstone Project: Build an End-to-End Agentic AI System" class="categoryLinkLabel_W154">Capstone Project: Build an End-to-End Agentic AI System</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Runut navigasi"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Halaman utama" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Planning, Memory, and Decision-Making</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Context Management and Retrieval</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">Pada halaman ini</button></div><div class="theme-doc-markdown markdown"><header><h1>Planning, Memory, and Decision-Making: Context Management and Retrieval</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Taut langsung ke Learning Objectives" title="Taut langsung ke Learning Objectives" translate="no">​</a></h2>
<ul>
<li class="">Manage limited context windows</li>
<li class="">Apply retrieval-augmented techniques</li>
<li class="">Design context compression strategies</li>
<li class="">Prevent context drift</li>
<li class="">Measure context relevance</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Taut langsung ke Introduction" title="Taut langsung ke Introduction" translate="no">​</a></h2>
<p>This chapter explains how agents manage limited context windows effectively.</p>
<hr>
<hr>
<p>Modern intelligent agents—such as large language model (LLM)-based systems, conversational assistants, and autonomous decision-making systems—operate under a fundamental constraint: <strong>they can only “see” a limited amount of information at one time</strong>. This limitation is commonly known as the <strong>context window constraint</strong>. Despite having access to massive external knowledge bases, tools, or long histories of interaction, an agent must decide <em>what information to bring into focus right now</em> in order to reason, plan, and act effectively.</p>
<p>This challenge is not new. Humans face a similar limitation with working memory: we can only actively think about a handful of concepts at once. Over centuries, humans developed techniques such as note-taking, summarization, prioritization, and memory aids to compensate. In a parallel way, artificial agents rely on <strong>context management strategies</strong>—planning what to include, what to omit, what to retrieve on demand, and how to compress information without losing meaning.</p>
<p>This chapter explores <strong>how agents manage limited context windows effectively</strong>, focusing on planning, memory, and decision-making. You will learn why context is limited, how agents prioritize and retrieve relevant information, how summarization enables context compression, how to prevent gradual loss of focus (context drift), and how to measure whether context management strategies are actually working.</p>
<p>Rather than treating context as a passive container, this chapter frames it as an <strong>active, carefully engineered resource</strong>—one that directly determines the quality, reliability, and usefulness of an agent’s decisions.</p>
<hr>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li class="">Understand and manage limited context windows in intelligent agents</li>
<li class="">Apply retrieval-augmented generation (RAG) techniques effectively</li>
<li class="">Design robust context compression and summarization strategies</li>
<li class="">Identify and prevent context drift in long-running interactions</li>
<li class="">Measure and evaluate context relevance and effectiveness</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="context-window-constraints">Context Window Constraints<a href="#context-window-constraints" class="hash-link" aria-label="Taut langsung ke Context Window Constraints" title="Taut langsung ke Context Window Constraints" translate="no">​</a></h2>
<p>Context windows define the maximum amount of information an agent can consider at once. In language-model-based agents, this typically means a fixed number of tokens that include system instructions, user input, conversation history, retrieved documents, and intermediate reasoning. While model sizes and context lengths have grown dramatically over time, <strong>the window is always finite</strong>, and scarcity forces trade-offs.</p>
<p>Historically, early language models had extremely small context windows, sometimes only a few hundred tokens. This made them brittle and forgetful, unable to maintain long conversations or complex reasoning chains. As context windows expanded into the thousands and now tens or hundreds of thousands of tokens, expectations grew accordingly. However, larger windows did not eliminate the problem; instead, they shifted it. The challenge became not <em>how to fit everything</em>, but <em>how to avoid overwhelming the model with irrelevant or low-value information</em>.</p>
<p>From a cognitive perspective, context windows resemble human working memory. Humans do not recall every detail of past experiences when making a decision; instead, we selectively recall what seems relevant. Similarly, agents must choose what to include in context based on current goals. Including too much information can be just as harmful as including too little, leading to confusion, slower inference, or incorrect reasoning.</p>
<p>Key implications of context window constraints include:</p>
<ul>
<li class=""><strong>Opportunity cost</strong>: Every token used for irrelevant history displaces potentially useful information.</li>
<li class=""><strong>Noise accumulation</strong>: Long conversations often contain tangents, corrections, or outdated assumptions.</li>
<li class=""><strong>Computational cost</strong>: Larger contexts increase latency and resource usage.</li>
<li class=""><strong>Reasoning degradation</strong>: Models may struggle to identify salient facts in overly dense contexts.</li>
</ul>
<p>A practical analogy is a <strong>meeting agenda</strong>. If every past discussion and document is read aloud in every meeting, participants lose focus and decision quality declines. Effective meetings summarize, prioritize, and distribute background materials selectively. Context windows demand the same discipline.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="typical-components-of-a-context-window">Typical Components of a Context Window<a href="#typical-components-of-a-context-window" class="hash-link" aria-label="Taut langsung ke Typical Components of a Context Window" title="Taut langsung ke Typical Components of a Context Window" translate="no">​</a></h3>
<table><thead><tr><th>Component</th><th>Description</th><th>Risk if Overused</th></tr></thead><tbody><tr><td>System instructions</td><td>Rules and behavior constraints</td><td>Crowding out task-specific info</td></tr><tr><td>Conversation history</td><td>Prior turns between user and agent</td><td>Irrelevant or outdated assumptions</td></tr><tr><td>Retrieved documents</td><td>External knowledge or memory</td><td>Information overload</td></tr><tr><td>Intermediate reasoning</td><td>Chain-of-thought or plans</td><td>Excess verbosity</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="visualizing-context-constraints">Visualizing Context Constraints<a href="#visualizing-context-constraints" class="hash-link" aria-label="Taut langsung ke Visualizing Context Constraints" title="Taut langsung ke Visualizing Context Constraints" translate="no">​</a></h3>
<!-- -->
<p>This diagram highlights that the context window is a <strong>shared budget</strong>, not an expandable container. Effective agents actively manage this budget rather than filling it passively.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="context-prioritization-techniques">Context Prioritization Techniques<a href="#context-prioritization-techniques" class="hash-link" aria-label="Taut langsung ke Context Prioritization Techniques" title="Taut langsung ke Context Prioritization Techniques" translate="no">​</a></h2>
<p>Context prioritization is the process of deciding <strong>what information deserves a place in the limited context window at a given moment</strong>. This is a planning problem as much as a memory problem. Without prioritization, agents default to chronological accumulation, which is almost always suboptimal.</p>
<p>The idea of prioritization emerged from early failures in long-running conversational systems. Developers noticed that simply appending conversation history led to degraded performance over time. Important constraints stated early were forgotten, while minor clarifications dominated the context. This led to the insight that <strong>recency is not the same as relevance</strong>.</p>
<p>At a conceptual level, prioritization answers three questions:</p>
<ol>
<li class="">What is the agent trying to achieve right now?</li>
<li class="">What information directly supports that goal?</li>
<li class="">What information can be safely omitted or summarized?</li>
</ol>
<p>Effective prioritization strategies often combine static rules with dynamic scoring. For example, system instructions may always be included, while conversation turns are filtered based on semantic relevance to the current task. Some systems use explicit metadata such as “importance scores” or “expiration times” attached to memories.</p>
<p>Common prioritization techniques include:</p>
<ul>
<li class=""><strong>Goal-based filtering</strong>: Include only information relevant to the current objective.</li>
<li class=""><strong>Recency-weighted relevance</strong>: Favor recent information <em>only if</em> it remains relevant.</li>
<li class=""><strong>Importance tagging</strong>: Mark critical facts (e.g., user preferences, constraints) as high-priority.</li>
<li class=""><strong>Hierarchical context</strong>: Keep summaries of older interactions rather than raw transcripts.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-customer-support-agent">Example: Customer Support Agent<a href="#example-customer-support-agent" class="hash-link" aria-label="Taut langsung ke Example: Customer Support Agent" title="Taut langsung ke Example: Customer Support Agent" translate="no">​</a></h3>
<p>Imagine a customer support agent assisting a user over several days. Early in the conversation, the user states they are on a free plan. Later, the discussion focuses on troubleshooting an advanced feature available only on paid plans. If the agent fails to prioritize the original plan information, it may give incorrect advice.</p>
<p>A well-prioritized context would:</p>
<ul>
<li class="">Retain the user’s plan type as a high-priority fact.</li>
<li class="">Summarize resolved troubleshooting steps.</li>
<li class="">Exclude casual greetings and small talk.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="context-prioritization-strategies-compared">Context Prioritization Strategies Compared<a href="#context-prioritization-strategies-compared" class="hash-link" aria-label="Taut langsung ke Context Prioritization Strategies Compared" title="Taut langsung ke Context Prioritization Strategies Compared" translate="no">​</a></h3>
<table><thead><tr><th>Strategy</th><th>Strengths</th><th>Weaknesses</th><th>Best Use Case</th></tr></thead><tbody><tr><td>Chronological</td><td>Simple to implement</td><td>Accumulates noise</td><td>Short interactions</td></tr><tr><td>Relevance-based</td><td>High signal-to-noise</td><td>Requires scoring</td><td>Knowledge-intensive tasks</td></tr><tr><td>Importance-tagged</td><td>Preserves key facts</td><td>Manual or heuristic tagging</td><td>Long-term agents</td></tr><tr><td>Hierarchical summaries</td><td>Compact and scalable</td><td>Risk of over-compression</td><td>Long conversations</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="prioritization-workflow">Prioritization Workflow<a href="#prioritization-workflow" class="hash-link" aria-label="Taut langsung ke Prioritization Workflow" title="Taut langsung ke Prioritization Workflow" translate="no">​</a></h3>
<!-- -->
<p>This workflow highlights that prioritization is not a one-time step but a <strong>continuous process</strong> that adapts as goals change.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="retrieval-augmented-generation">Retrieval-Augmented Generation<a href="#retrieval-augmented-generation" class="hash-link" aria-label="Taut langsung ke Retrieval-Augmented Generation" title="Taut langsung ke Retrieval-Augmented Generation" translate="no">​</a></h2>
<p>Retrieval-augmented generation (RAG) addresses context limitations by <strong>decoupling knowledge storage from reasoning context</strong>. Instead of forcing all relevant information into the context window permanently, agents retrieve only what is needed at the moment of generation.</p>
<p>The concept of RAG emerged as a response to two competing realities: models have powerful reasoning abilities, but they are expensive and limited in context; external databases are vast and cheap, but lack reasoning. RAG bridges this gap by combining retrieval systems (search, vector databases) with generative models.</p>
<p>At a high level, RAG works as follows:</p>
<ol>
<li class="">The agent receives a query or task.</li>
<li class="">The query is transformed into a search representation (e.g., embeddings).</li>
<li class="">Relevant documents or memories are retrieved from external storage.</li>
<li class="">Retrieved content is inserted into the context window.</li>
<li class="">The model generates a response grounded in retrieved information.</li>
</ol>
<p>This approach allows agents to scale knowledge without scaling context windows. However, it introduces new challenges, such as retrieval accuracy, redundancy, and trustworthiness of retrieved content.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="rag-architecture-overview">RAG Architecture Overview<a href="#rag-architecture-overview" class="hash-link" aria-label="Taut langsung ke RAG Architecture Overview" title="Taut langsung ke RAG Architecture Overview" translate="no">​</a></h3>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-rag-matters">Why RAG Matters<a href="#why-rag-matters" class="hash-link" aria-label="Taut langsung ke Why RAG Matters" title="Taut langsung ke Why RAG Matters" translate="no">​</a></h3>
<p>RAG is particularly valuable when:</p>
<ul>
<li class="">Knowledge changes frequently (e.g., policies, documentation).</li>
<li class="">The knowledge base is too large to fit into context.</li>
<li class="">Accuracy and grounding are critical (e.g., legal or medical domains).</li>
</ul>
<p>Without RAG, agents rely on parametric memory (what they were trained on), which may be outdated or incomplete. With RAG, agents gain <strong>situational awareness</strong>, pulling in fresh and relevant data on demand.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-study-enterprise-knowledge-assistant">Case Study: Enterprise Knowledge Assistant<a href="#case-study-enterprise-knowledge-assistant" class="hash-link" aria-label="Taut langsung ke Case Study: Enterprise Knowledge Assistant" title="Taut langsung ke Case Study: Enterprise Knowledge Assistant" translate="no">​</a></h3>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-study-scaling-knowledge-access-in-a-global-consulting-firm">Case Study: Scaling Knowledge Access in a Global Consulting Firm<a href="#case-study-scaling-knowledge-access-in-a-global-consulting-firm" class="hash-link" aria-label="Taut langsung ke Case Study: Scaling Knowledge Access in a Global Consulting Firm" title="Taut langsung ke Case Study: Scaling Knowledge Access in a Global Consulting Firm" translate="no">​</a></h2>
<p><strong>Context</strong><br>
<!-- -->A global consulting firm with tens of thousands of employees maintained an internal knowledge base containing project reports, best practices, and industry analyses. Consultants frequently struggled to find relevant information quickly, especially under tight deadlines. Leadership decided to deploy an AI assistant to help consultants query this knowledge base conversationally.</p>
<p><strong>Problem</strong><br>
<!-- -->Initial prototypes attempted to load large chunks of documentation into the model’s context. This quickly failed. Context windows overflowed, responses became inconsistent, and the assistant often cited irrelevant projects. The sheer volume of information made naive approaches unusable.</p>
<p><strong>Solution</strong><br>
<!-- -->The team implemented a retrieval-augmented generation system. All documents were chunked and embedded into a vector database. When a consultant asked a question, the system retrieved the top relevant chunks and inserted them into the context. Careful prompt design ensured the model cited retrieved sources explicitly.</p>
<p><strong>Results</strong><br>
<!-- -->Consultants reported dramatically faster access to relevant information. Average research time dropped from hours to minutes. Importantly, response accuracy improved because answers were grounded in specific, retrieved documents rather than vague generalizations.</p>
<p><strong>Lessons Learned</strong><br>
<!-- -->The team learned that retrieval quality mattered as much as model quality. Poor chunking or embedding strategies led to irrelevant retrievals, undermining trust. RAG was not a silver bullet, but when carefully designed, it transformed how context limitations were handled.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summarization-for-context-compression">Summarization for Context Compression<a href="#summarization-for-context-compression" class="hash-link" aria-label="Taut langsung ke Summarization for Context Compression" title="Taut langsung ke Summarization for Context Compression" translate="no">​</a></h2>
<p>Summarization is one of the most powerful tools for managing limited context windows. Instead of choosing between including or excluding information, summarization allows agents to <strong>compress information while preserving meaning</strong>. This mirrors human strategies such as taking meeting notes or writing executive summaries.</p>
<p>Historically, summarization has been studied as a natural language processing task in its own right. In the context of agents, however, summarization serves a strategic purpose: maintaining continuity over long interactions without overwhelming the context window.</p>
<p>There are multiple types of summarization used in context management:</p>
<ul>
<li class=""><strong>Extractive summarization</strong>: Selecting key sentences verbatim.</li>
<li class=""><strong>Abstractive summarization</strong>: Generating new text that captures core ideas.</li>
<li class=""><strong>Rolling summaries</strong>: Periodically updating a summary as interactions progress.</li>
<li class=""><strong>Hierarchical summaries</strong>: Summaries of summaries at different time scales.</li>
</ul>
<p>The challenge lies in deciding <em>what to preserve</em>. Over-aggressive summarization can remove subtle constraints or emotional nuances. Under-aggressive summarization fails to save enough space.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-personal-productivity-agent">Example: Personal Productivity Agent<a href="#example-personal-productivity-agent" class="hash-link" aria-label="Taut langsung ke Example: Personal Productivity Agent" title="Taut langsung ke Example: Personal Productivity Agent" translate="no">​</a></h3>
<p>A productivity agent helping a user plan a multi-month project might summarize weekly discussions into milestones, decisions, and open questions. Detailed task discussions are compressed, but commitments and deadlines are preserved.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="summarization-trade-offs">Summarization Trade-Offs<a href="#summarization-trade-offs" class="hash-link" aria-label="Taut langsung ke Summarization Trade-Offs" title="Taut langsung ke Summarization Trade-Offs" translate="no">​</a></h3>
<table><thead><tr><th>Aspect</th><th>High Compression</th><th>Low Compression</th></tr></thead><tbody><tr><td>Context size</td><td>Small</td><td>Large</td></tr><tr><td>Detail retention</td><td>Low</td><td>High</td></tr><tr><td>Risk</td><td>Losing nuance</td><td>Overloading context</td></tr><tr><td>Best use</td><td>Long histories</td><td>Short, complex tasks</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="summarization-lifecycle">Summarization Lifecycle<a href="#summarization-lifecycle" class="hash-link" aria-label="Taut langsung ke Summarization Lifecycle" title="Taut langsung ke Summarization Lifecycle" translate="no">​</a></h3>
<!-- -->
<p>Summarization is not a one-off step; it is a <strong>living process</strong> that evolves with the interaction.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="preventing-context-drift">Preventing Context Drift<a href="#preventing-context-drift" class="hash-link" aria-label="Taut langsung ke Preventing Context Drift" title="Taut langsung ke Preventing Context Drift" translate="no">​</a></h2>
<p>Context drift occurs when an agent gradually loses alignment with the original goal, constraints, or user intent. This is especially common in long-running conversations or autonomous agents that operate over extended periods.</p>
<p>Drift often emerges subtly. A small assumption goes unchallenged, a summary omits a key constraint, or retrieved information shifts the focus. Over time, the agent’s internal representation diverges from reality. Humans experience similar drift when discussions wander off-topic or when memories are reconstructed inaccurately.</p>
<p>Preventing context drift requires both <strong>technical mechanisms</strong> and <strong>interaction design principles</strong>. Technically, agents can anchor critical constraints explicitly and reintroduce them periodically. Design-wise, agents can ask clarifying questions or restate goals to confirm alignment.</p>
<p>Common anti-drift techniques include:</p>
<ul>
<li class=""><strong>Goal restatement</strong>: Periodically restating the current objective.</li>
<li class=""><strong>Constraint pinning</strong>: Keeping non-negotiable constraints always in context.</li>
<li class=""><strong>Drift detection</strong>: Monitoring when responses deviate from expected topics.</li>
<li class=""><strong>User checkpoints</strong>: Asking users to confirm or correct direction.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="drift-prevention-flow">Drift Prevention Flow<a href="#drift-prevention-flow" class="hash-link" aria-label="Taut langsung ke Drift Prevention Flow" title="Taut langsung ke Drift Prevention Flow" translate="no">​</a></h3>
<!-- -->
<p>Preventing drift is less about perfection and more about <strong>early correction</strong>. Small course adjustments prevent large failures later.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="measuring-context-effectiveness">Measuring Context Effectiveness<a href="#measuring-context-effectiveness" class="hash-link" aria-label="Taut langsung ke Measuring Context Effectiveness" title="Taut langsung ke Measuring Context Effectiveness" translate="no">​</a></h2>
<p>Managing context is only useful if it improves outcomes. Measuring context effectiveness helps teams move from intuition to evidence. Without metrics, it is impossible to know whether prioritization, retrieval, or summarization strategies are helping or hurting.</p>
<p>Metrics can be qualitative or quantitative. Qualitative signals include user satisfaction and perceived coherence. Quantitative metrics include task success rates, hallucination frequency, or retrieval precision. Importantly, metrics should align with the agent’s purpose.</p>
<p>Common evaluation dimensions include:</p>
<ul>
<li class=""><strong>Relevance</strong>: Does the context support the current task?</li>
<li class=""><strong>Efficiency</strong>: How many tokens are used per successful outcome?</li>
<li class=""><strong>Stability</strong>: Does performance degrade over time?</li>
<li class=""><strong>Faithfulness</strong>: Are responses grounded in provided context?</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-metrics-table">Example Metrics Table<a href="#example-metrics-table" class="hash-link" aria-label="Taut langsung ke Example Metrics Table" title="Taut langsung ke Example Metrics Table" translate="no">​</a></h3>
<table><thead><tr><th>Metric</th><th>What It Measures</th><th>Why It Matters</th></tr></thead><tbody><tr><td>Task success rate</td><td>Completion accuracy</td><td>Overall effectiveness</td></tr><tr><td>Token efficiency</td><td>Tokens per task</td><td>Cost and scalability</td></tr><tr><td>Drift frequency</td><td>Goal deviation</td><td>Reliability</td></tr><tr><td>Retrieval precision</td><td>Relevant docs retrieved</td><td>Grounding quality</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="measurement-feedback-loop">Measurement Feedback Loop<a href="#measurement-feedback-loop" class="hash-link" aria-label="Taut langsung ke Measurement Feedback Loop" title="Taut langsung ke Measurement Feedback Loop" translate="no">​</a></h3>
<!-- -->
<p>Measurement turns context management from an art into an engineering discipline.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Taut langsung ke Summary" title="Taut langsung ke Summary" translate="no">​</a></h2>
<p>Context management lies at the heart of effective planning, memory, and decision-making in intelligent agents. Because context windows are inherently limited, agents must treat context as a scarce and valuable resource. Through prioritization, retrieval-augmented generation, summarization, drift prevention, and rigorous measurement, agents can operate far beyond the apparent limits of their context windows.</p>
<p>Rather than asking, “How can we fit everything in?” the better question is, “What does the agent truly need <em>right now</em> to make the best decision?” Answering that question well is the essence of context management.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="reflection-questions">Reflection Questions<a href="#reflection-questions" class="hash-link" aria-label="Taut langsung ke Reflection Questions" title="Taut langsung ke Reflection Questions" translate="no">​</a></h2>
<ol>
<li class="">How does context management in artificial agents mirror human cognitive strategies?</li>
<li class="">What risks arise from relying too heavily on summarization?</li>
<li class="">In what situations might retrieval-augmented generation fail or mislead an agent?</li>
<li class="">How would you design metrics for a safety-critical agent (e.g., healthcare)?</li>
<li class="">What strategies would you use to prevent context drift in a multi-week interaction?</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Halaman dokumentasi"><a class="pagination-nav__link pagination-nav__link--prev" href="/module-5-planning-memory-decision/chapter-2"><div class="pagination-nav__sublabel">Sebelum</div><div class="pagination-nav__label">Vector Databases and Long-Term Memory</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/module-5-planning-memory-decision/chapter-4"><div class="pagination-nav__sublabel">Berikut</div><div class="pagination-nav__label">Decision-Making Under Uncertainty</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#context-window-constraints" class="table-of-contents__link toc-highlight">Context Window Constraints</a><ul><li><a href="#typical-components-of-a-context-window" class="table-of-contents__link toc-highlight">Typical Components of a Context Window</a></li><li><a href="#visualizing-context-constraints" class="table-of-contents__link toc-highlight">Visualizing Context Constraints</a></li></ul></li><li><a href="#context-prioritization-techniques" class="table-of-contents__link toc-highlight">Context Prioritization Techniques</a><ul><li><a href="#example-customer-support-agent" class="table-of-contents__link toc-highlight">Example: Customer Support Agent</a></li><li><a href="#context-prioritization-strategies-compared" class="table-of-contents__link toc-highlight">Context Prioritization Strategies Compared</a></li><li><a href="#prioritization-workflow" class="table-of-contents__link toc-highlight">Prioritization Workflow</a></li></ul></li><li><a href="#retrieval-augmented-generation" class="table-of-contents__link toc-highlight">Retrieval-Augmented Generation</a><ul><li><a href="#rag-architecture-overview" class="table-of-contents__link toc-highlight">RAG Architecture Overview</a></li><li><a href="#why-rag-matters" class="table-of-contents__link toc-highlight">Why RAG Matters</a></li><li><a href="#case-study-enterprise-knowledge-assistant" class="table-of-contents__link toc-highlight">Case Study: Enterprise Knowledge Assistant</a></li></ul></li><li><a href="#case-study-scaling-knowledge-access-in-a-global-consulting-firm" class="table-of-contents__link toc-highlight">Case Study: Scaling Knowledge Access in a Global Consulting Firm</a></li><li><a href="#summarization-for-context-compression" class="table-of-contents__link toc-highlight">Summarization for Context Compression</a><ul><li><a href="#example-personal-productivity-agent" class="table-of-contents__link toc-highlight">Example: Personal Productivity Agent</a></li><li><a href="#summarization-trade-offs" class="table-of-contents__link toc-highlight">Summarization Trade-Offs</a></li><li><a href="#summarization-lifecycle" class="table-of-contents__link toc-highlight">Summarization Lifecycle</a></li></ul></li><li><a href="#preventing-context-drift" class="table-of-contents__link toc-highlight">Preventing Context Drift</a><ul><li><a href="#drift-prevention-flow" class="table-of-contents__link toc-highlight">Drift Prevention Flow</a></li></ul></li><li><a href="#measuring-context-effectiveness" class="table-of-contents__link toc-highlight">Measuring Context Effectiveness</a><ul><li><a href="#example-metrics-table" class="table-of-contents__link toc-highlight">Example Metrics Table</a></li><li><a href="#measurement-feedback-loop" class="table-of-contents__link toc-highlight">Measurement Feedback Loop</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#reflection-questions" class="table-of-contents__link toc-highlight">Reflection Questions</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Learning Materials. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>