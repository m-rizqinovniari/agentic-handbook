<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-5-planning-memory-decision/chapter-4" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Decision-Making Under Uncertainty | Learning Materials</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://localhost:3000/en/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="http://localhost:3000/en/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="http://localhost:3000/en/module-5-planning-memory-decision/chapter-4"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Decision-Making Under Uncertainty | Learning Materials"><meta data-rh="true" name="description" content="Learning Objectives"><meta data-rh="true" property="og:description" content="Learning Objectives"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="http://localhost:3000/en/module-5-planning-memory-decision/chapter-4"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-5-planning-memory-decision/chapter-4" hreflang="id"><link data-rh="true" rel="alternate" href="http://localhost:3000/en/module-5-planning-memory-decision/chapter-4" hreflang="en"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-5-planning-memory-decision/chapter-4" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Decision-Making Under Uncertainty","item":"http://localhost:3000/en/module-5-planning-memory-decision/chapter-4"}]}</script><link rel="stylesheet" href="/en/assets/css/styles.b3bb77c0.css">
<script src="/en/assets/js/runtime~main.5ee8e820.js" defer="defer"></script>
<script src="/en/assets/js/main.684f60bd.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Learning Materials</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/module-5-planning-memory-decision/chapter-4" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/en/module-5-planning-memory-decision/chapter-4" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/"><span title="Deep Dive into Agentic AI: Design, Implementation, and Production Systems" class="linkLabel_WmDU">Deep Dive into Agentic AI: Design, Implementation, and Production Systems</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-1-introduction-agentic-ai/chapter-1"><span title="Introduction to Agentic AI and Autonomous Systems" class="categoryLinkLabel_W154">Introduction to Agentic AI and Autonomous Systems</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-2-core-components/chapter-1"><span title="Core Components of an AI Agent" class="categoryLinkLabel_W154">Core Components of an AI Agent</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-3-architectures-patterns/chapter-1"><span title="Agent Architectures and Design Patterns" class="categoryLinkLabel_W154">Agent Architectures and Design Patterns</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-4-agent-frameworks/chapter-1"><span title="Building Agents with Modern Frameworks" class="categoryLinkLabel_W154">Building Agents with Modern Frameworks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/en/module-5-planning-memory-decision/chapter-1"><span title="Planning, Memory, and Decision-Making" class="categoryLinkLabel_W154">Planning, Memory, and Decision-Making</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-5-planning-memory-decision/chapter-1"><span title="Task Decomposition and Planning Strategies" class="linkLabel_WmDU">Task Decomposition and Planning Strategies</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-5-planning-memory-decision/chapter-2"><span title="Vector Databases and Long-Term Memory" class="linkLabel_WmDU">Vector Databases and Long-Term Memory</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-5-planning-memory-decision/chapter-3"><span title="Context Management and Retrieval" class="linkLabel_WmDU">Context Management and Retrieval</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/module-5-planning-memory-decision/chapter-4"><span title="Decision-Making Under Uncertainty" class="linkLabel_WmDU">Decision-Making Under Uncertainty</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-6-multi-agent/chapter-1"><span title="Multi-Agent Systems and Collaboration" class="categoryLinkLabel_W154">Multi-Agent Systems and Collaboration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-7-evaluation-safety/chapter-1"><span title="Evaluation, Safety, and Alignment" class="categoryLinkLabel_W154">Evaluation, Safety, and Alignment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-8-scaling-production/chapter-1"><span title="Scaling, Optimization, and Production Deployment" class="categoryLinkLabel_W154">Scaling, Optimization, and Production Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-9-capstone/chapter-1"><span title="Capstone Project: Build an End-to-End Agentic AI System" class="categoryLinkLabel_W154">Capstone Project: Build an End-to-End Agentic AI System</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Planning, Memory, and Decision-Making</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Decision-Making Under Uncertainty</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Planning, Memory, and Decision-Making: Decision-Making Under Uncertainty</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives" translate="no">​</a></h2>
<ul>
<li class="">Identify uncertainty sources</li>
<li class="">Apply heuristic decision strategies</li>
<li class="">Estimate confidence in decisions</li>
<li class="">Design risk-aware actions</li>
<li class="">Evaluate decision quality</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>This chapter focuses on probabilistic and heuristic decision-making.</p>
<hr>
<hr>
<p>Decision-making under uncertainty lies at the heart of intelligent behavior—whether in humans, organizations, or artificial agents. Every day, people make choices without knowing all the facts: a doctor diagnoses with incomplete test results, a business invests without knowing future market conditions, and an autonomous vehicle navigates streets where pedestrians behave unpredictably. In artificial intelligence (AI) and agent systems, uncertainty is not an edge case—it is the default condition.</p>
<p>This chapter explores how intelligent agents plan, remember, and decide when the world is uncertain. Rather than assuming perfect information or fully predictable environments, we focus on <strong>probabilistic reasoning, heuristic strategies, confidence estimation, and risk-aware decision-making</strong>. These ideas allow agents to act effectively even when they cannot be certain about outcomes.</p>
<p>Historically, early AI systems struggled outside controlled environments because they relied on rigid rules and deterministic logic. As AI moved into real-world applications—finance, healthcare, robotics, and online platforms—it became clear that uncertainty must be explicitly modeled and managed. This realization led to the development of probabilistic models, heuristics inspired by human reasoning, and mechanisms for evaluating and improving decisions over time.</p>
<p>By the end of this chapter, you will not only understand <em>what</em> uncertainty is, but <em>why it matters</em>, <em>how agents cope with it</em>, and <em>how decision quality can be evaluated and improved</em>. The concepts presented here form the foundation for robust, adaptive, and trustworthy intelligent systems.</p>
<hr>
<p>By completing this chapter, you will be able to:</p>
<ul>
<li class="">Identify and categorize different sources of uncertainty in agent systems</li>
<li class="">Apply heuristic decision-making strategies appropriately</li>
<li class="">Estimate and interpret confidence in decisions</li>
<li class="">Design and justify risk-aware action selection mechanisms</li>
<li class="">Evaluate the quality and effectiveness of decisions over time</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="sources-of-uncertainty-in-agent-systems">Sources of Uncertainty in Agent Systems<a href="#sources-of-uncertainty-in-agent-systems" class="hash-link" aria-label="Direct link to Sources of Uncertainty in Agent Systems" title="Direct link to Sources of Uncertainty in Agent Systems" translate="no">​</a></h2>
<p>Uncertainty in agent systems arises when an agent lacks complete, accurate, or reliable information about itself, its environment, or the consequences of its actions. This is not a flaw in design—it is an inherent property of operating in complex, real-world settings. Understanding the <em>sources</em> of uncertainty is the first step toward managing it effectively.</p>
<p>Historically, classical decision theory assumed that uncertainty could be reduced to known probabilities. However, as agent systems became more sophisticated and autonomous, researchers recognized multiple layers of uncertainty that go beyond simple randomness. These layers interact with perception, memory, learning, and planning, making uncertainty a systemic challenge rather than a single variable.</p>
<p>One major source of uncertainty is <strong>perceptual uncertainty</strong>. Sensors—whether cameras, microphones, or data feeds—are noisy and incomplete. For example, a delivery drone’s camera may misinterpret shadows as obstacles, or a recommendation system may infer user preferences from sparse or misleading data. This uncertainty propagates forward: flawed perceptions lead to flawed beliefs, which influence decisions.</p>
<p>Another important source is <strong>environmental uncertainty</strong>. Even with perfect perception, the environment itself may be unpredictable. Weather changes, human behavior, market fluctuations, and system failures introduce variability that cannot be fully anticipated. This type of uncertainty is often modeled probabilistically, but in many cases, the probability distributions themselves are unknown or shifting.</p>
<p>A third source comes from <strong>model uncertainty</strong>. Agents rely on internal models to predict outcomes, but these models are simplifications of reality. Assumptions may be outdated, incomplete, or wrong. For instance, a traffic prediction model trained before a major city redesign may systematically misestimate congestion patterns.</p>
<p>Finally, <strong>action outcome uncertainty</strong> reflects the fact that actions do not always produce intended results. Mechanical failures, delayed effects, or interactions with other agents can alter outcomes. Even simple actions like “send a message” can fail due to network issues or human interpretation.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="common-categories-of-uncertainty">Common Categories of Uncertainty<a href="#common-categories-of-uncertainty" class="hash-link" aria-label="Direct link to Common Categories of Uncertainty" title="Direct link to Common Categories of Uncertainty" translate="no">​</a></h3>
<ul>
<li class=""><strong>Aleatoric uncertainty</strong>: inherent randomness (e.g., dice rolls, weather variation)</li>
<li class=""><strong>Epistemic uncertainty</strong>: lack of knowledge that could, in principle, be reduced</li>
<li class=""><strong>Adversarial uncertainty</strong>: caused by other agents with competing goals</li>
<li class=""><strong>Temporal uncertainty</strong>: uncertainty about how situations evolve over time</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-sources-of-uncertainty-and-examples">Table: Sources of Uncertainty and Examples<a href="#table-sources-of-uncertainty-and-examples" class="hash-link" aria-label="Direct link to Table: Sources of Uncertainty and Examples" title="Direct link to Table: Sources of Uncertainty and Examples" translate="no">​</a></h3>
<table><thead><tr><th>Source of Uncertainty</th><th>Description</th><th>Real-World Example</th></tr></thead><tbody><tr><td>Perceptual</td><td>Incomplete or noisy observations</td><td>Face recognition errors in low light</td></tr><tr><td>Environmental</td><td>Unpredictable external changes</td><td>Sudden stock market shifts</td></tr><tr><td>Model</td><td>Incorrect or outdated internal models</td><td>Misestimated demand forecasting</td></tr><tr><td>Action Outcome</td><td>Actions produce variable results</td><td>Robot arm slipping during grasp</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="visualizing-uncertainty-flow-in-an-agent">Visualizing Uncertainty Flow in an Agent<a href="#visualizing-uncertainty-flow-in-an-agent" class="hash-link" aria-label="Direct link to Visualizing Uncertainty Flow in an Agent" title="Direct link to Visualizing Uncertainty Flow in an Agent" translate="no">​</a></h3>
<!-- -->
<p>Understanding these sources allows designers to choose appropriate strategies—probabilistic models, heuristics, or fallback mechanisms—rather than assuming certainty where none exists.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="heuristic-decision-making">Heuristic Decision-Making<a href="#heuristic-decision-making" class="hash-link" aria-label="Direct link to Heuristic Decision-Making" title="Direct link to Heuristic Decision-Making" translate="no">​</a></h2>
<p>Heuristic decision-making refers to the use of simplified rules or strategies that guide choices under uncertainty. Unlike optimal decision-making—which attempts to compute the best possible action by exhaustively evaluating outcomes—heuristics prioritize speed, efficiency, and practicality. They are especially valuable when time, data, or computational resources are limited.</p>
<p>The concept of heuristics emerged prominently from cognitive psychology in the 1970s, particularly through the work of Herbert Simon and later Daniel Kahneman and Amos Tversky. Simon introduced the idea of <strong>bounded rationality</strong>, arguing that real decision-makers cannot optimize perfectly because of cognitive and environmental constraints. Instead, they “satisfice”—they look for solutions that are good enough.</p>
<p>In agent systems, heuristics play a similar role. For example, a game-playing agent may use a rule like “control the center early” instead of calculating all future board states. A recommendation system might prioritize popular items rather than exploring the entire catalog. These shortcuts often perform surprisingly well, especially in familiar or structured environments.</p>
<p>However, heuristics are not random guesses. They are typically grounded in experience, domain knowledge, or statistical regularities. For instance, the <strong>availability heuristic</strong> favors options that are easier to recall, while the <strong>greedy heuristic</strong> chooses the locally best option at each step. In algorithms like A* search, heuristics estimate remaining cost to guide exploration efficiently.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-heuristics-matter">Why Heuristics Matter<a href="#why-heuristics-matter" class="hash-link" aria-label="Direct link to Why Heuristics Matter" title="Direct link to Why Heuristics Matter" translate="no">​</a></h3>
<ul>
<li class="">Reduce computational complexity</li>
<li class="">Enable real-time decision-making</li>
<li class="">Provide robustness when models are incomplete</li>
<li class="">Mimic effective human decision strategies</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="advantages-and-limitations">Advantages and Limitations<a href="#advantages-and-limitations" class="hash-link" aria-label="Direct link to Advantages and Limitations" title="Direct link to Advantages and Limitations" translate="no">​</a></h3>
<p>Heuristics shine in environments where exact solutions are impractical. However, they can introduce systematic biases. A heuristic that works well in one context may fail badly in another, especially if underlying conditions change. Therefore, heuristic decision-making must be combined with monitoring, confidence estimation, and evaluation.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-common-heuristics-in-agent-systems">Table: Common Heuristics in Agent Systems<a href="#table-common-heuristics-in-agent-systems" class="hash-link" aria-label="Direct link to Table: Common Heuristics in Agent Systems" title="Direct link to Table: Common Heuristics in Agent Systems" translate="no">​</a></h3>
<table><thead><tr><th>Heuristic</th><th>Core Idea</th><th>Typical Use Case</th><th>Limitation</th></tr></thead><tbody><tr><td>Greedy</td><td>Choose best immediate option</td><td>Routing, scheduling</td><td>Can miss global optimum</td></tr><tr><td>Rule-based</td><td>If-then rules</td><td>Expert systems</td><td>Brittle to novel cases</td></tr><tr><td>Availability</td><td>Prefer familiar options</td><td>Recommendation systems</td><td>Bias toward popular items</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="heuristic-decision-flow">Heuristic Decision Flow<a href="#heuristic-decision-flow" class="hash-link" aria-label="Direct link to Heuristic Decision Flow" title="Direct link to Heuristic Decision Flow" translate="no">​</a></h3>
<!-- -->
<p>Heuristics are not a replacement for probabilistic reasoning—they are a complementary tool that allows agents to act effectively when full reasoning is infeasible.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="confidence-estimation">Confidence Estimation<a href="#confidence-estimation" class="hash-link" aria-label="Direct link to Confidence Estimation" title="Direct link to Confidence Estimation" translate="no">​</a></h2>
<p>Confidence estimation is the process by which an agent assesses how reliable its own decisions or predictions are. This concept is critical because acting without knowing <em>how sure you are</em> can be as dangerous as not acting at all. Confidence influences whether an agent proceeds, seeks more information, or defers to another system or human.</p>
<p>Historically, confidence estimation grew out of statistics and probability theory, particularly in the form of confidence intervals and Bayesian posterior probabilities. In AI, confidence estimation expanded to include model uncertainty, ensemble disagreement, and calibration techniques.</p>
<p>At a basic level, confidence can be represented as a probability: “There is a 90% chance this diagnosis is correct.” More sophisticated systems consider multiple dimensions of confidence, such as data quality, model agreement, and historical performance in similar situations.</p>
<p>Confidence estimation plays a key role in <strong>human-AI interaction</strong>. A medical AI that reports high confidence may be trusted more, while low confidence can prompt human review. Importantly, overconfidence is a serious risk—systems that appear confident but are wrong can cause harm.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-confidence-is-estimated">How Confidence Is Estimated<a href="#how-confidence-is-estimated" class="hash-link" aria-label="Direct link to How Confidence Is Estimated" title="Direct link to How Confidence Is Estimated" translate="no">​</a></h3>
<ul>
<li class="">Probabilistic outputs (e.g., softmax probabilities)</li>
<li class="">Bayesian posterior distributions</li>
<li class="">Ensemble variance (disagreement among models)</li>
<li class="">Historical accuracy tracking</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-confidence-estimation-methods">Table: Confidence Estimation Methods<a href="#table-confidence-estimation-methods" class="hash-link" aria-label="Direct link to Table: Confidence Estimation Methods" title="Direct link to Table: Confidence Estimation Methods" translate="no">​</a></h3>
<table><thead><tr><th>Method</th><th>How It Works</th><th>Strength</th><th>Weakness</th></tr></thead><tbody><tr><td>Probability Scores</td><td>Direct model output</td><td>Simple, fast</td><td>Often miscalibrated</td></tr><tr><td>Bayesian Inference</td><td>Posterior uncertainty</td><td>Principled</td><td>Computationally heavy</td></tr><tr><td>Ensembles</td><td>Compare multiple models</td><td>Robust</td><td>Resource-intensive</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="confidence-in-decision-pipelines">Confidence in Decision Pipelines<a href="#confidence-in-decision-pipelines" class="hash-link" aria-label="Direct link to Confidence in Decision Pipelines" title="Direct link to Confidence in Decision Pipelines" translate="no">​</a></h3>
<!-- -->
<p>Effective confidence estimation enables agents to behave cautiously when needed and decisively when appropriate.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-aware-action-selection">Risk-Aware Action Selection<a href="#risk-aware-action-selection" class="hash-link" aria-label="Direct link to Risk-Aware Action Selection" title="Direct link to Risk-Aware Action Selection" translate="no">​</a></h2>
<p>Risk-aware action selection extends decision-making beyond expected value to include potential negative outcomes. While two actions may have the same expected reward, their risk profiles can differ dramatically. A risk-aware agent recognizes this difference and chooses actions aligned with its tolerance for failure.</p>
<p>This idea has roots in economics and finance, particularly in portfolio theory, where investors balance return against risk. In AI, risk awareness became critical as systems moved into safety-critical domains such as healthcare, aviation, and autonomous driving.</p>
<p>Risk can be defined in multiple ways: probability of failure, magnitude of loss, or worst-case outcomes. Risk-aware agents often incorporate <strong>utility functions</strong> that penalize undesirable outcomes more heavily than they reward positive ones.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-strategies">Risk Strategies<a href="#risk-strategies" class="hash-link" aria-label="Direct link to Risk Strategies" title="Direct link to Risk Strategies" translate="no">​</a></h3>
<ul>
<li class=""><strong>Risk-averse</strong>: prioritize safety and stability</li>
<li class=""><strong>Risk-neutral</strong>: focus on expected value</li>
<li class=""><strong>Risk-seeking</strong>: tolerate uncertainty for higher payoff</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-risk-profiles-compared">Table: Risk Profiles Compared<a href="#table-risk-profiles-compared" class="hash-link" aria-label="Direct link to Table: Risk Profiles Compared" title="Direct link to Table: Risk Profiles Compared" translate="no">​</a></h3>
<table><thead><tr><th>Profile</th><th>Behavior</th><th>Suitable Context</th></tr></thead><tbody><tr><td>Risk-averse</td><td>Avoids high-variance actions</td><td>Medical diagnosis</td></tr><tr><td>Risk-neutral</td><td>Maximizes expected reward</td><td>Online advertising</td></tr><tr><td>Risk-seeking</td><td>Explores uncertain gains</td><td>Game playing, R&amp;D</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="risk-aware-decision-flow">Risk-Aware Decision Flow<a href="#risk-aware-decision-flow" class="hash-link" aria-label="Direct link to Risk-Aware Decision Flow" title="Direct link to Risk-Aware Decision Flow" translate="no">​</a></h3>
<!-- -->
<p>Risk-aware selection ensures that agents behave responsibly, especially when stakes are high.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="fallback-and-escalation-strategies">Fallback and Escalation Strategies<a href="#fallback-and-escalation-strategies" class="hash-link" aria-label="Direct link to Fallback and Escalation Strategies" title="Direct link to Fallback and Escalation Strategies" translate="no">​</a></h2>
<p>Fallback and escalation strategies define what an agent should do when uncertainty becomes too high or confidence too low. Instead of forcing a decision, the agent can switch to safer alternatives or request assistance.</p>
<p>These strategies are common in aviation, where autopilot systems hand control back to pilots under abnormal conditions. In AI, fallback mechanisms prevent catastrophic failures and improve trustworthiness.</p>
<p>Fallbacks may involve simpler models, conservative actions, or predefined safe states. Escalation often means involving a human or a more powerful system.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="examples-of-fallbacks">Examples of Fallbacks<a href="#examples-of-fallbacks" class="hash-link" aria-label="Direct link to Examples of Fallbacks" title="Direct link to Examples of Fallbacks" translate="no">​</a></h3>
<ul>
<li class="">Switching to rule-based control</li>
<li class="">Slowing down or stopping movement</li>
<li class="">Asking for human confirmation</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="escalation-logic">Escalation Logic<a href="#escalation-logic" class="hash-link" aria-label="Direct link to Escalation Logic" title="Direct link to Escalation Logic" translate="no">​</a></h3>
<!-- -->
<p>Designing effective fallback strategies requires anticipating failure modes and defining clear thresholds.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluating-decision-outcomes">Evaluating Decision Outcomes<a href="#evaluating-decision-outcomes" class="hash-link" aria-label="Direct link to Evaluating Decision Outcomes" title="Direct link to Evaluating Decision Outcomes" translate="no">​</a></h2>
<p>Evaluating decision outcomes closes the decision-making loop. Without evaluation, agents cannot learn, adapt, or improve. Evaluation involves comparing expected outcomes with actual results and updating models accordingly.</p>
<p>Historically, evaluation metrics evolved from simple accuracy measures to more nuanced concepts like regret, robustness, and long-term impact. In uncertain environments, a single bad outcome does not necessarily imply a bad decision—it may reflect unavoidable randomness.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluation-dimensions">Evaluation Dimensions<a href="#evaluation-dimensions" class="hash-link" aria-label="Direct link to Evaluation Dimensions" title="Direct link to Evaluation Dimensions" translate="no">​</a></h3>
<ul>
<li class="">Outcome quality (reward, cost)</li>
<li class="">Consistency over time</li>
<li class="">Robustness to uncertainty</li>
<li class="">Alignment with risk preferences</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-decision-evaluation-metrics">Table: Decision Evaluation Metrics<a href="#table-decision-evaluation-metrics" class="hash-link" aria-label="Direct link to Table: Decision Evaluation Metrics" title="Direct link to Table: Decision Evaluation Metrics" translate="no">​</a></h3>
<table><thead><tr><th>Metric</th><th>What It Measures</th><th>When Useful</th></tr></thead><tbody><tr><td>Accuracy</td><td>Correct vs incorrect</td><td>Classification tasks</td></tr><tr><td>Regret</td><td>Missed opportunity</td><td>Sequential decisions</td></tr><tr><td>Utility</td><td>Overall value</td><td>Multi-objective tasks</td></tr></tbody></table>
<p>Evaluation informs future planning and heuristic adjustment, making decision-making a continuous improvement process.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-study-autonomous-delivery-robots-in-urban-environments">Case Study: Autonomous Delivery Robots in Urban Environments<a href="#case-study-autonomous-delivery-robots-in-urban-environments" class="hash-link" aria-label="Direct link to Case Study: Autonomous Delivery Robots in Urban Environments" title="Direct link to Case Study: Autonomous Delivery Robots in Urban Environments" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="context">Context<a href="#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context" translate="no">​</a></h3>
<p>In the late 2010s, several logistics companies began deploying small autonomous delivery robots on city sidewalks. These robots operated in dense urban environments filled with pedestrians, pets, bicycles, construction zones, and unpredictable weather. The goal was to reduce last-mile delivery costs while maintaining safety and reliability.</p>
<p>The robots were equipped with cameras, lidar sensors, and GPS, and they operated semi-autonomously, with human supervisors monitoring multiple robots at once. From the beginning, uncertainty was a defining challenge.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="problem">Problem<a href="#problem" class="hash-link" aria-label="Direct link to Problem" title="Direct link to Problem" translate="no">​</a></h3>
<p>The robots faced constant perceptual uncertainty: sensor noise, occlusions, and ambiguous objects. Environmental uncertainty compounded the problem, as pedestrian behavior varied widely across neighborhoods and times of day.</p>
<p>Early decision systems relied on deterministic rules, which led to frequent stops or overly cautious behavior. In some cases, robots froze in place, blocking sidewalks, while in others they made risky crossings.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="solution">Solution<a href="#solution" class="hash-link" aria-label="Direct link to Solution" title="Direct link to Solution" translate="no">​</a></h3>
<p>Engineers redesigned the decision system to explicitly model uncertainty. Probabilistic perception outputs were combined with heuristic navigation rules. Confidence estimation determined when the robot should proceed, slow down, or request human intervention.</p>
<p>Risk-aware action selection was introduced: crossing a street was treated as a high-risk action with strict confidence thresholds. Fallback strategies included pulling over to a safe spot and escalating to a remote operator.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results" translate="no">​</a></h3>
<p>The new system reduced incidents by over 40% and increased delivery completion rates. Robots moved more smoothly, and human interventions became more targeted and efficient.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="lessons-learned">Lessons Learned<a href="#lessons-learned" class="hash-link" aria-label="Direct link to Lessons Learned" title="Direct link to Lessons Learned" translate="no">​</a></h3>
<ul>
<li class="">Uncertainty must be embraced, not ignored</li>
<li class="">Confidence estimation enables safer autonomy</li>
<li class="">Fallback strategies are essential for public trust</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>Decision-making under uncertainty is a foundational challenge for intelligent agents. By understanding sources of uncertainty, applying heuristics, estimating confidence, selecting risk-aware actions, and evaluating outcomes, agents can operate effectively in complex, unpredictable environments. These mechanisms transform uncertainty from a barrier into a manageable aspect of intelligent behavior.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="reflection-questions">Reflection Questions<a href="#reflection-questions" class="hash-link" aria-label="Direct link to Reflection Questions" title="Direct link to Reflection Questions" translate="no">​</a></h2>
<ol>
<li class="">Which source of uncertainty do you think is hardest to manage, and why?</li>
<li class="">When might a heuristic outperform a fully probabilistic approach?</li>
<li class="">How can overconfidence in AI systems be detected and mitigated?</li>
<li class="">What trade-offs arise when designing risk-averse versus risk-seeking agents?</li>
<li class="">How would you design a fallback strategy for a system you use daily?</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/module-5-planning-memory-decision/chapter-3"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Context Management and Retrieval</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/module-6-multi-agent/chapter-1"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Agent Roles and Specialization</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#sources-of-uncertainty-in-agent-systems" class="table-of-contents__link toc-highlight">Sources of Uncertainty in Agent Systems</a><ul><li><a href="#common-categories-of-uncertainty" class="table-of-contents__link toc-highlight">Common Categories of Uncertainty</a></li><li><a href="#table-sources-of-uncertainty-and-examples" class="table-of-contents__link toc-highlight">Table: Sources of Uncertainty and Examples</a></li><li><a href="#visualizing-uncertainty-flow-in-an-agent" class="table-of-contents__link toc-highlight">Visualizing Uncertainty Flow in an Agent</a></li></ul></li><li><a href="#heuristic-decision-making" class="table-of-contents__link toc-highlight">Heuristic Decision-Making</a><ul><li><a href="#why-heuristics-matter" class="table-of-contents__link toc-highlight">Why Heuristics Matter</a></li><li><a href="#advantages-and-limitations" class="table-of-contents__link toc-highlight">Advantages and Limitations</a></li><li><a href="#table-common-heuristics-in-agent-systems" class="table-of-contents__link toc-highlight">Table: Common Heuristics in Agent Systems</a></li><li><a href="#heuristic-decision-flow" class="table-of-contents__link toc-highlight">Heuristic Decision Flow</a></li></ul></li><li><a href="#confidence-estimation" class="table-of-contents__link toc-highlight">Confidence Estimation</a><ul><li><a href="#how-confidence-is-estimated" class="table-of-contents__link toc-highlight">How Confidence Is Estimated</a></li><li><a href="#table-confidence-estimation-methods" class="table-of-contents__link toc-highlight">Table: Confidence Estimation Methods</a></li><li><a href="#confidence-in-decision-pipelines" class="table-of-contents__link toc-highlight">Confidence in Decision Pipelines</a></li></ul></li><li><a href="#risk-aware-action-selection" class="table-of-contents__link toc-highlight">Risk-Aware Action Selection</a><ul><li><a href="#risk-strategies" class="table-of-contents__link toc-highlight">Risk Strategies</a></li><li><a href="#table-risk-profiles-compared" class="table-of-contents__link toc-highlight">Table: Risk Profiles Compared</a></li><li><a href="#risk-aware-decision-flow" class="table-of-contents__link toc-highlight">Risk-Aware Decision Flow</a></li></ul></li><li><a href="#fallback-and-escalation-strategies" class="table-of-contents__link toc-highlight">Fallback and Escalation Strategies</a><ul><li><a href="#examples-of-fallbacks" class="table-of-contents__link toc-highlight">Examples of Fallbacks</a></li><li><a href="#escalation-logic" class="table-of-contents__link toc-highlight">Escalation Logic</a></li></ul></li><li><a href="#evaluating-decision-outcomes" class="table-of-contents__link toc-highlight">Evaluating Decision Outcomes</a><ul><li><a href="#evaluation-dimensions" class="table-of-contents__link toc-highlight">Evaluation Dimensions</a></li><li><a href="#table-decision-evaluation-metrics" class="table-of-contents__link toc-highlight">Table: Decision Evaluation Metrics</a></li></ul></li><li><a href="#case-study-autonomous-delivery-robots-in-urban-environments" class="table-of-contents__link toc-highlight">Case Study: Autonomous Delivery Robots in Urban Environments</a><ul><li><a href="#context" class="table-of-contents__link toc-highlight">Context</a></li><li><a href="#problem" class="table-of-contents__link toc-highlight">Problem</a></li><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#lessons-learned" class="table-of-contents__link toc-highlight">Lessons Learned</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#reflection-questions" class="table-of-contents__link toc-highlight">Reflection Questions</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Learning Materials. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>