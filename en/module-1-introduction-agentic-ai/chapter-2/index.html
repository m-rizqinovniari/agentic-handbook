<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-1-introduction-agentic-ai/chapter-2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Autonomy, Agency, and Goal-Oriented Behavior | Learning Materials</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://localhost:3000/en/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="http://localhost:3000/en/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Autonomy, Agency, and Goal-Oriented Behavior | Learning Materials"><meta data-rh="true" name="description" content="Learning Objectives"><meta data-rh="true" property="og:description" content="Learning Objectives"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-2"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-1-introduction-agentic-ai/chapter-2" hreflang="id"><link data-rh="true" rel="alternate" href="http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-2" hreflang="en"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-1-introduction-agentic-ai/chapter-2" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Autonomy, Agency, and Goal-Oriented Behavior","item":"http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-2"}]}</script><link rel="stylesheet" href="/en/assets/css/styles.b3bb77c0.css">
<script src="/en/assets/js/runtime~main.5ee8e820.js" defer="defer"></script>
<script src="/en/assets/js/main.684f60bd.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Learning Materials</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/module-1-introduction-agentic-ai/chapter-2" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/en/module-1-introduction-agentic-ai/chapter-2" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/"><span title="Deep Dive into Agentic AI: Design, Implementation, and Production Systems" class="linkLabel_WmDU">Deep Dive into Agentic AI: Design, Implementation, and Production Systems</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/en/module-1-introduction-agentic-ai/chapter-1"><span title="Introduction to Agentic AI and Autonomous Systems" class="categoryLinkLabel_W154">Introduction to Agentic AI and Autonomous Systems</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-1"><span title="What Is Agentic AI?" class="linkLabel_WmDU">What Is Agentic AI?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-2"><span title="Autonomy, Agency, and Goal-Oriented Behavior" class="linkLabel_WmDU">Autonomy, Agency, and Goal-Oriented Behavior</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-3"><span title="Agentic AI vs Traditional AI and LLM Applications" class="linkLabel_WmDU">Agentic AI vs Traditional AI and LLM Applications</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-4"><span title="Real-World Use Cases and Current Limitations" class="linkLabel_WmDU">Real-World Use Cases and Current Limitations</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-2-core-components/chapter-1"><span title="Core Components of an AI Agent" class="categoryLinkLabel_W154">Core Components of an AI Agent</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-3-architectures-patterns/chapter-1"><span title="Agent Architectures and Design Patterns" class="categoryLinkLabel_W154">Agent Architectures and Design Patterns</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-4-agent-frameworks/chapter-1"><span title="Building Agents with Modern Frameworks" class="categoryLinkLabel_W154">Building Agents with Modern Frameworks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-5-planning-memory-decision/chapter-1"><span title="Planning, Memory, and Decision-Making" class="categoryLinkLabel_W154">Planning, Memory, and Decision-Making</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-6-multi-agent/chapter-1"><span title="Multi-Agent Systems and Collaboration" class="categoryLinkLabel_W154">Multi-Agent Systems and Collaboration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-7-evaluation-safety/chapter-1"><span title="Evaluation, Safety, and Alignment" class="categoryLinkLabel_W154">Evaluation, Safety, and Alignment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-8-scaling-production/chapter-1"><span title="Scaling, Optimization, and Production Deployment" class="categoryLinkLabel_W154">Scaling, Optimization, and Production Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-9-capstone/chapter-1"><span title="Capstone Project: Build an End-to-End Agentic AI System" class="categoryLinkLabel_W154">Capstone Project: Build an End-to-End Agentic AI System</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Introduction to Agentic AI and Autonomous Systems</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Autonomy, Agency, and Goal-Oriented Behavior</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Introduction to Agentic AI and Autonomous Systems: Autonomy, Agency, and Goal-Oriented Behavior</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives" translate="no">​</a></h2>
<ul>
<li class="">Explain different levels of agent autonomy with examples</li>
<li class="">Distinguish agency from simple automation pipelines</li>
<li class="">Describe how goals are represented internally by agents</li>
<li class="">Analyze how feedback from the environment affects agent behavior</li>
<li class="">Evaluate autonomy trade-offs in practical system design</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>This chapter dives deeper into autonomy and agency, explaining how agents make decisions independently and pursue goals over time within dynamic environments.</p>
<hr>
<hr>
<p>Artificial Intelligence has evolved from simple rule-based programs into systems that can <strong>act independently, pursue objectives over time, and adapt to changing environments</strong>. These systems are often described as <em>agentic AI</em> or <em>autonomous systems</em>. Unlike traditional software that executes predefined instructions, agentic AI systems can decide <strong>what to do next</strong>, <strong>when to do it</strong>, and sometimes even <strong>why</strong>—within the boundaries set by their designers.</p>
<p>This chapter explores the foundational ideas behind agentic AI, focusing specifically on <strong>autonomy</strong>, <strong>agency</strong>, and <strong>goal-oriented behavior</strong>. These concepts are not just theoretical; they shape how self-driving cars navigate streets, how digital assistants manage tasks, how trading bots operate in financial markets, and how robotic systems collaborate with humans in factories and hospitals.</p>
<p>Understanding these ideas is crucial because increasing autonomy brings both <strong>power and responsibility</strong>. Highly autonomous systems can improve efficiency, scalability, and responsiveness—but they also introduce challenges related to control, predictability, safety, and ethics. This chapter builds a deep conceptual framework that helps you reason about how autonomous agents are designed, how they behave, and what trade-offs engineers must navigate.</p>
<hr>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li class="">Explain different levels of agent autonomy using clear, real-world examples</li>
<li class="">Distinguish true agency from simple automation pipelines</li>
<li class="">Describe how goals and objectives are represented internally within agents</li>
<li class="">Analyze how environmental feedback loops shape agent behavior over time</li>
<li class="">Evaluate trade-offs between human control and system autonomy in practical designs</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="degrees-of-autonomy-in-ai-systems">Degrees of Autonomy in AI Systems<a href="#degrees-of-autonomy-in-ai-systems" class="hash-link" aria-label="Direct link to Degrees of Autonomy in AI Systems" title="Direct link to Degrees of Autonomy in AI Systems" translate="no">​</a></h2>
<p>Autonomy in AI refers to the <strong>degree to which a system can operate without direct human intervention</strong>. Importantly, autonomy is not a binary property. Systems are not simply “autonomous” or “not autonomous”; instead, they exist along a <strong>spectrum of autonomy</strong>, ranging from fully manual tools to highly self-governing agents.</p>
<p>Historically, early software systems exhibited <em>zero autonomy</em>. They executed explicit instructions written by humans and stopped when those instructions ended. As computing power and algorithmic sophistication increased, systems gained limited autonomy through conditional logic, feedback control, and eventually machine learning. Today’s agentic AI systems represent the most advanced point on this continuum, capable of making decisions under uncertainty and over extended time horizons.</p>
<p>At the lowest level of autonomy, systems function as <strong>assistive tools</strong>. For example, a spell checker highlights potential errors but leaves all decisions to the user. Slightly higher on the spectrum are <strong>rule-based automated systems</strong>, such as thermostats that turn heating on or off based on temperature thresholds. While these systems act automatically, they do not reason beyond predefined rules.</p>
<p>More advanced systems exhibit <strong>conditional autonomy</strong>. These systems can select among multiple actions based on context, such as adaptive cruise control in cars or recommendation systems that adjust suggestions based on user behavior. At the highest levels, <strong>fully autonomous agents</strong> can plan, learn, and act continuously, such as warehouse robots coordinating logistics or AI agents managing cloud infrastructure.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="levels-of-autonomy-overview">Levels of Autonomy Overview<a href="#levels-of-autonomy-overview" class="hash-link" aria-label="Direct link to Levels of Autonomy Overview" title="Direct link to Levels of Autonomy Overview" translate="no">​</a></h3>
<table><thead><tr><th>Level of Autonomy</th><th>Description</th><th>Example Systems</th><th>Human Role</th></tr></thead><tbody><tr><td>Manual</td><td>No autonomous behavior</td><td>Calculator</td><td>Full control</td></tr><tr><td>Assisted</td><td>Suggestions only</td><td>Spell checkers</td><td>Decision-maker</td></tr><tr><td>Automated</td><td>Rule-based actions</td><td>Thermostats</td><td>Setup &amp; override</td></tr><tr><td>Semi-autonomous</td><td>Context-aware decisions</td><td>Adaptive cruise control</td><td>Supervision</td></tr><tr><td>Fully autonomous</td><td>Goal-driven, adaptive behavior</td><td>Self-driving vehicles</td><td>Governance</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-degrees-of-autonomy-matter">Why Degrees of Autonomy Matter<a href="#why-degrees-of-autonomy-matter" class="hash-link" aria-label="Direct link to Why Degrees of Autonomy Matter" title="Direct link to Why Degrees of Autonomy Matter" translate="no">​</a></h3>
<p>Understanding degrees of autonomy helps designers:</p>
<ul>
<li class="">Match system capability to <strong>risk level</strong></li>
<li class="">Determine appropriate <strong>human oversight</strong></li>
<li class="">Balance flexibility with <strong>safety and predictability</strong></li>
</ul>
<p>A medical diagnostic AI, for instance, may be intentionally designed with <strong>limited autonomy</strong>, providing recommendations rather than decisions. In contrast, an AI managing data center cooling systems might operate with near-total autonomy because the risks are lower and rapid responses are valuable.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="visualizing-autonomy-progression">Visualizing Autonomy Progression<a href="#visualizing-autonomy-progression" class="hash-link" aria-label="Direct link to Visualizing Autonomy Progression" title="Direct link to Visualizing Autonomy Progression" translate="no">​</a></h3>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="agency-vs-automation-key-distinctions">Agency vs Automation: Key Distinctions<a href="#agency-vs-automation-key-distinctions" class="hash-link" aria-label="Direct link to Agency vs Automation: Key Distinctions" title="Direct link to Agency vs Automation: Key Distinctions" translate="no">​</a></h2>
<p>Automation and agency are often confused, but they represent fundamentally different system capabilities. <strong>Automation</strong> focuses on executing predefined processes efficiently, while <strong>agency</strong> involves the capacity to act <strong>intentionally</strong> toward goals within an environment.</p>
<p>An automated system follows a script. An agentic system interprets a situation, evaluates options, and selects actions based on internal objectives. For example, an automated email responder sends replies based on templates. An agentic customer-support AI can decide whether to escalate an issue, ask follow-up questions, or delay action based on context and past interactions.</p>
<p>Agency implies three essential characteristics:</p>
<ul>
<li class=""><strong>Perception</strong>: The ability to observe the environment</li>
<li class=""><strong>Decision-making</strong>: The ability to choose among actions</li>
<li class=""><strong>Intentionality</strong>: The pursuit of goals over time</li>
</ul>
<p>Automation lacks intentionality. It does not “want” an outcome; it simply executes steps. Agency, by contrast, requires an internal model of success and failure.</p>
<p>Historically, automation dominated industrial systems because it was predictable and safe. As environments became more dynamic—think online markets or urban traffic—pure automation proved insufficient. Systems needed to adapt in real time, which drove the rise of agent-based approaches.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="automation-vs-agency-comparison">Automation vs Agency Comparison<a href="#automation-vs-agency-comparison" class="hash-link" aria-label="Direct link to Automation vs Agency Comparison" title="Direct link to Automation vs Agency Comparison" translate="no">​</a></h3>
<table><thead><tr><th>Aspect</th><th>Automation</th><th>Agency</th></tr></thead><tbody><tr><td>Flexibility</td><td>Low</td><td>High</td></tr><tr><td>Decision-making</td><td>Predefined rules</td><td>Contextual reasoning</td></tr><tr><td>Goal awareness</td><td>None</td><td>Explicit</td></tr><tr><td>Adaptation</td><td>Minimal</td><td>Continuous</td></tr><tr><td>Example</td><td>Assembly line robot</td><td>Delivery drone</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="everyday-analogy">Everyday Analogy<a href="#everyday-analogy" class="hash-link" aria-label="Direct link to Everyday Analogy" title="Direct link to Everyday Analogy" translate="no">​</a></h3>
<p>Consider a washing machine versus a human housekeeper:</p>
<ul>
<li class="">The washing machine follows a fixed program—automation.</li>
<li class="">The housekeeper decides what to wash first, adapts to stains, and manages time—agency.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interaction-flow-of-an-agent">Interaction Flow of an Agent<a href="#interaction-flow-of-an-agent" class="hash-link" aria-label="Direct link to Interaction Flow of an Agent" title="Direct link to Interaction Flow of an Agent" translate="no">​</a></h3>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="goal-representation-and-internal-objectives">Goal Representation and Internal Objectives<a href="#goal-representation-and-internal-objectives" class="hash-link" aria-label="Direct link to Goal Representation and Internal Objectives" title="Direct link to Goal Representation and Internal Objectives" translate="no">​</a></h2>
<p>Goals are the <strong>driving force behind agent behavior</strong>. Without goals, an agent cannot evaluate whether one action is better than another. Internally, goals can be represented in multiple ways, depending on system complexity and application domain.</p>
<p>Early AI systems used <strong>explicit symbolic goals</strong>, such as logical conditions (“reach location X”). Modern systems often rely on <strong>numerical objectives</strong>, such as maximizing a reward function. Reinforcement learning popularized this approach, framing goals as long-term reward maximization.</p>
<p>More sophisticated agents maintain <strong>hierarchical goals</strong>. For example, a delivery robot may have a top-level goal of completing deliveries efficiently, sub-goals for navigating streets, and micro-goals for avoiding obstacles. This mirrors human goal structures and improves scalability.</p>
<p>Goal representation also influences <strong>interpretability</strong>. Explicit goals are easier to understand and audit, while learned objectives may be opaque but more flexible. Designers must carefully choose representations based on system requirements.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="types-of-goal-representations">Types of Goal Representations<a href="#types-of-goal-representations" class="hash-link" aria-label="Direct link to Types of Goal Representations" title="Direct link to Types of Goal Representations" translate="no">​</a></h3>
<table><thead><tr><th>Goal Type</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>Symbolic</td><td>Logical conditions</td><td>Puzzle-solving agents</td></tr><tr><td>Numerical</td><td>Reward functions</td><td>Game-playing AI</td></tr><tr><td>Hierarchical</td><td>Nested objectives</td><td>Robotics</td></tr><tr><td>Multi-objective</td><td>Trade-off optimization</td><td>Energy management</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="goal-evaluation-loop">Goal Evaluation Loop<a href="#goal-evaluation-loop" class="hash-link" aria-label="Direct link to Goal Evaluation Loop" title="Direct link to Goal Evaluation Loop" translate="no">​</a></h3>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="environment-modeling-and-feedback-loops">Environment Modeling and Feedback Loops<a href="#environment-modeling-and-feedback-loops" class="hash-link" aria-label="Direct link to Environment Modeling and Feedback Loops" title="Direct link to Environment Modeling and Feedback Loops" translate="no">​</a></h2>
<p>An agent’s behavior is shaped by how it <strong>models its environment</strong> and how it responds to feedback. The environment includes everything external to the agent: physical space, digital systems, other agents, and humans.</p>
<p>Simple agents use <strong>reactive models</strong>, responding directly to observations. More advanced agents build <strong>internal representations</strong>, such as maps or predictive models, allowing them to anticipate future states. These models enable planning and long-term reasoning.</p>
<p>Feedback loops are essential. After acting, an agent observes the consequences and updates its internal state. Over time, this loop enables learning, adaptation, and improvement. Poor feedback design can lead to unstable or unintended behaviors.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="feedback-loop-structure">Feedback Loop Structure<a href="#feedback-loop-structure" class="hash-link" aria-label="Direct link to Feedback Loop Structure" title="Direct link to Feedback Loop Structure" translate="no">​</a></h3>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-feedback-matters">Why Feedback Matters<a href="#why-feedback-matters" class="hash-link" aria-label="Direct link to Why Feedback Matters" title="Direct link to Why Feedback Matters" translate="no">​</a></h3>
<ul>
<li class="">Enables learning from mistakes</li>
<li class="">Supports adaptation in dynamic environments</li>
<li class="">Helps detect goal misalignment</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="constraints-incentives-and-reward-structures">Constraints, Incentives, and Reward Structures<a href="#constraints-incentives-and-reward-structures" class="hash-link" aria-label="Direct link to Constraints, Incentives, and Reward Structures" title="Direct link to Constraints, Incentives, and Reward Structures" translate="no">​</a></h2>
<p>No agent operates in a vacuum. <strong>Constraints</strong> define what actions are allowed, <strong>incentives</strong> shape preferences, and <strong>reward structures</strong> translate goals into measurable signals.</p>
<p>Constraints may be physical (battery limits), legal (compliance rules), or ethical (safety boundaries). Incentives guide behavior by making some outcomes more attractive than others. Rewards operationalize incentives in computational terms.</p>
<p>Poorly designed reward structures can lead to <strong>reward hacking</strong>, where agents exploit loopholes to maximize reward without achieving the intended goal. This highlights the importance of aligning incentives with real-world objectives.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="constraint-and-reward-design-considerations">Constraint and Reward Design Considerations<a href="#constraint-and-reward-design-considerations" class="hash-link" aria-label="Direct link to Constraint and Reward Design Considerations" title="Direct link to Constraint and Reward Design Considerations" translate="no">​</a></h3>
<table><thead><tr><th>Element</th><th>Purpose</th><th>Risk if Misdesigned</th></tr></thead><tbody><tr><td>Constraints</td><td>Safety &amp; legality</td><td>Over-restriction</td></tr><tr><td>Incentives</td><td>Behavioral guidance</td><td>Misalignment</td></tr><tr><td>Rewards</td><td>Learning signal</td><td>Exploitation</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="trade-offs-between-control-and-autonomy">Trade-offs Between Control and Autonomy<a href="#trade-offs-between-control-and-autonomy" class="hash-link" aria-label="Direct link to Trade-offs Between Control and Autonomy" title="Direct link to Trade-offs Between Control and Autonomy" translate="no">​</a></h2>
<p>Increasing autonomy reduces human workload but also reduces <strong>direct control</strong>. This trade-off is central to agentic system design. Too much control limits adaptability; too much autonomy risks unpredictability.</p>
<p>Designers often implement <strong>shared autonomy</strong>, where humans set high-level goals and agents handle execution. This approach balances flexibility with oversight, common in aviation and healthcare.</p>
<p>Key considerations include:</p>
<ul>
<li class="">Risk tolerance</li>
<li class="">System criticality</li>
<li class="">Trust and transparency</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-study-autonomous-warehouse-robots-at-scale">Case Study: Autonomous Warehouse Robots at Scale<a href="#case-study-autonomous-warehouse-robots-at-scale" class="hash-link" aria-label="Direct link to Case Study: Autonomous Warehouse Robots at Scale" title="Direct link to Case Study: Autonomous Warehouse Robots at Scale" translate="no">​</a></h2>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="context">Context<a href="#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context" translate="no">​</a></h2>
<p>In the early 2010s, large e-commerce companies faced growing pressure to fulfill orders faster while managing massive warehouses. Human-operated systems struggled with scalability and error rates.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="problem">Problem<a href="#problem" class="hash-link" aria-label="Direct link to Problem" title="Direct link to Problem" translate="no">​</a></h2>
<p>Manual picking was slow and error-prone. Traditional automation lacked flexibility to adapt to changing inventory layouts and demand spikes.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="solution">Solution<a href="#solution" class="hash-link" aria-label="Direct link to Solution" title="Direct link to Solution" translate="no">​</a></h2>
<p>Companies deployed fleets of autonomous mobile robots with goal-oriented navigation. Each robot acted as an agent, optimizing routes while coordinating with others through shared goals and constraints.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results" translate="no">​</a></h2>
<p>Order fulfillment times dropped dramatically, error rates decreased, and warehouse throughput increased. However, initial deployments faced challenges in coordination and safety tuning.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="lessons-learned">Lessons Learned<a href="#lessons-learned" class="hash-link" aria-label="Direct link to Lessons Learned" title="Direct link to Lessons Learned" translate="no">​</a></h2>
<ul>
<li class="">Moderate autonomy with strong constraints proved most effective</li>
<li class="">Clear goal hierarchies improved coordination</li>
<li class="">Human oversight remained essential for exception handling</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>This chapter explored the foundations of agentic AI and autonomous systems. You learned how autonomy exists on a spectrum, how agency differs from automation, how goals drive behavior, and how feedback, constraints, and incentives shape outcomes. Most importantly, you examined the trade-offs designers face when balancing control and independence.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="reflection-questions">Reflection Questions<a href="#reflection-questions" class="hash-link" aria-label="Direct link to Reflection Questions" title="Direct link to Reflection Questions" translate="no">​</a></h2>
<ol>
<li class="">Where should autonomy be limited, even if technology allows more independence?</li>
<li class="">How can poorly designed rewards lead to harmful behavior in agents?</li>
<li class="">What types of systems benefit most from shared autonomy rather than full autonomy?</li>
<li class="">How might goal transparency affect trust in autonomous systems?</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/module-1-introduction-agentic-ai/chapter-1"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">What Is Agentic AI?</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/module-1-introduction-agentic-ai/chapter-3"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Agentic AI vs Traditional AI and LLM Applications</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#degrees-of-autonomy-in-ai-systems" class="table-of-contents__link toc-highlight">Degrees of Autonomy in AI Systems</a><ul><li><a href="#levels-of-autonomy-overview" class="table-of-contents__link toc-highlight">Levels of Autonomy Overview</a></li><li><a href="#why-degrees-of-autonomy-matter" class="table-of-contents__link toc-highlight">Why Degrees of Autonomy Matter</a></li><li><a href="#visualizing-autonomy-progression" class="table-of-contents__link toc-highlight">Visualizing Autonomy Progression</a></li></ul></li><li><a href="#agency-vs-automation-key-distinctions" class="table-of-contents__link toc-highlight">Agency vs Automation: Key Distinctions</a><ul><li><a href="#automation-vs-agency-comparison" class="table-of-contents__link toc-highlight">Automation vs Agency Comparison</a></li><li><a href="#everyday-analogy" class="table-of-contents__link toc-highlight">Everyday Analogy</a></li><li><a href="#interaction-flow-of-an-agent" class="table-of-contents__link toc-highlight">Interaction Flow of an Agent</a></li></ul></li><li><a href="#goal-representation-and-internal-objectives" class="table-of-contents__link toc-highlight">Goal Representation and Internal Objectives</a><ul><li><a href="#types-of-goal-representations" class="table-of-contents__link toc-highlight">Types of Goal Representations</a></li><li><a href="#goal-evaluation-loop" class="table-of-contents__link toc-highlight">Goal Evaluation Loop</a></li></ul></li><li><a href="#environment-modeling-and-feedback-loops" class="table-of-contents__link toc-highlight">Environment Modeling and Feedback Loops</a><ul><li><a href="#feedback-loop-structure" class="table-of-contents__link toc-highlight">Feedback Loop Structure</a></li><li><a href="#why-feedback-matters" class="table-of-contents__link toc-highlight">Why Feedback Matters</a></li></ul></li><li><a href="#constraints-incentives-and-reward-structures" class="table-of-contents__link toc-highlight">Constraints, Incentives, and Reward Structures</a><ul><li><a href="#constraint-and-reward-design-considerations" class="table-of-contents__link toc-highlight">Constraint and Reward Design Considerations</a></li></ul></li><li><a href="#trade-offs-between-control-and-autonomy" class="table-of-contents__link toc-highlight">Trade-offs Between Control and Autonomy</a></li><li><a href="#case-study-autonomous-warehouse-robots-at-scale" class="table-of-contents__link toc-highlight">Case Study: Autonomous Warehouse Robots at Scale</a></li><li><a href="#context" class="table-of-contents__link toc-highlight">Context</a></li><li><a href="#problem" class="table-of-contents__link toc-highlight">Problem</a></li><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#lessons-learned" class="table-of-contents__link toc-highlight">Lessons Learned</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#reflection-questions" class="table-of-contents__link toc-highlight">Reflection Questions</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Learning Materials. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>