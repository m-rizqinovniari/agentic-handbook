<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-1-introduction-agentic-ai/chapter-4" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Real-World Use Cases and Current Limitations | Learning Materials</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://localhost:3000/en/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="http://localhost:3000/en/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-4"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Real-World Use Cases and Current Limitations | Learning Materials"><meta data-rh="true" name="description" content="Learning Objectives"><meta data-rh="true" property="og:description" content="Learning Objectives"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-4"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-1-introduction-agentic-ai/chapter-4" hreflang="id"><link data-rh="true" rel="alternate" href="http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-4" hreflang="en"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-1-introduction-agentic-ai/chapter-4" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Real-World Use Cases and Current Limitations","item":"http://localhost:3000/en/module-1-introduction-agentic-ai/chapter-4"}]}</script><link rel="stylesheet" href="/en/assets/css/styles.b3bb77c0.css">
<script src="/en/assets/js/runtime~main.5ee8e820.js" defer="defer"></script>
<script src="/en/assets/js/main.684f60bd.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Learning Materials</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/module-1-introduction-agentic-ai/chapter-4" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/en/module-1-introduction-agentic-ai/chapter-4" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/"><span title="Deep Dive into Agentic AI: Design, Implementation, and Production Systems" class="linkLabel_WmDU">Deep Dive into Agentic AI: Design, Implementation, and Production Systems</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/en/module-1-introduction-agentic-ai/chapter-1"><span title="Introduction to Agentic AI and Autonomous Systems" class="categoryLinkLabel_W154">Introduction to Agentic AI and Autonomous Systems</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-1"><span title="What Is Agentic AI?" class="linkLabel_WmDU">What Is Agentic AI?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-2"><span title="Autonomy, Agency, and Goal-Oriented Behavior" class="linkLabel_WmDU">Autonomy, Agency, and Goal-Oriented Behavior</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-3"><span title="Agentic AI vs Traditional AI and LLM Applications" class="linkLabel_WmDU">Agentic AI vs Traditional AI and LLM Applications</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/module-1-introduction-agentic-ai/chapter-4"><span title="Real-World Use Cases and Current Limitations" class="linkLabel_WmDU">Real-World Use Cases and Current Limitations</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-2-core-components/chapter-1"><span title="Core Components of an AI Agent" class="categoryLinkLabel_W154">Core Components of an AI Agent</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-3-architectures-patterns/chapter-1"><span title="Agent Architectures and Design Patterns" class="categoryLinkLabel_W154">Agent Architectures and Design Patterns</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-4-agent-frameworks/chapter-1"><span title="Building Agents with Modern Frameworks" class="categoryLinkLabel_W154">Building Agents with Modern Frameworks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-5-planning-memory-decision/chapter-1"><span title="Planning, Memory, and Decision-Making" class="categoryLinkLabel_W154">Planning, Memory, and Decision-Making</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-6-multi-agent/chapter-1"><span title="Multi-Agent Systems and Collaboration" class="categoryLinkLabel_W154">Multi-Agent Systems and Collaboration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-7-evaluation-safety/chapter-1"><span title="Evaluation, Safety, and Alignment" class="categoryLinkLabel_W154">Evaluation, Safety, and Alignment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-8-scaling-production/chapter-1"><span title="Scaling, Optimization, and Production Deployment" class="categoryLinkLabel_W154">Scaling, Optimization, and Production Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/module-9-capstone/chapter-1"><span title="Capstone Project: Build an End-to-End Agentic AI System" class="categoryLinkLabel_W154">Capstone Project: Build an End-to-End Agentic AI System</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Introduction to Agentic AI and Autonomous Systems</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Real-World Use Cases and Current Limitations</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Introduction to Agentic AI and Autonomous Systems: Real-World Use Cases and Current Limitations</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives" translate="no">​</a></h2>
<ul>
<li class="">Identify at least three real-world applications of Agentic AI</li>
<li class="">Analyze strengths and weaknesses of deployed systems</li>
<li class="">Explain key technical limitations of current agents</li>
<li class="">Assess operational risks in real-world environments</li>
<li class="">Summarize open challenges in Agentic AI research</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>This chapter surveys real-world applications of Agentic AI while critically examining technical, operational, and ethical limitations.</p>
<hr>
<hr>
<p>Over the past decade, artificial intelligence has moved from being a largely passive tool—responding to user queries or executing predefined scripts—toward something far more dynamic and autonomous. This shift has given rise to <strong>Agentic AI</strong>: systems designed not only to generate outputs, but to <em>act</em>, <em>decide</em>, <em>plan</em>, and <em>adapt</em> toward achieving goals in complex, real-world environments. These systems are often described as <strong>autonomous agents</strong> because they operate with a degree of independence from direct human control.</p>
<p>Agentic AI now appears in many familiar places: research assistants that design experiments, enterprise agents that coordinate workflows, and consumer tools that book travel, manage finances, or control smart homes. At the same time, these systems raise significant questions. Can we trust an agent to act reliably? What happens when it fails? How do latency, cost, and uncertainty limit real-world deployment? And how do humans feel about delegating meaningful decisions to machines?</p>
<p>This chapter surveys <strong>real-world applications of Agentic AI</strong> while critically examining their <strong>technical, operational, and ethical limitations</strong>. Rather than focusing only on what is possible, we will explore what is <em>actually deployed today</em>, what works well, what breaks down, and why. By the end of this chapter, you should have a balanced, realistic understanding of Agentic AI—not as science fiction, but as an evolving technology with both promise and constraints.</p>
<hr>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li class="">Identify at least three real-world applications of Agentic AI across research, enterprise, and consumer domains</li>
<li class="">Analyze the strengths and weaknesses of deployed agentic systems</li>
<li class="">Explain key technical limitations of current agents, including reliability and latency</li>
<li class="">Assess operational risks and maintenance challenges in real-world environments</li>
<li class="">Summarize future directions and open research problems in Agentic AI</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="agentic-ai-in-research-enterprise-and-consumer-tools">Agentic AI in Research, Enterprise, and Consumer Tools<a href="#agentic-ai-in-research-enterprise-and-consumer-tools" class="hash-link" aria-label="Direct link to Agentic AI in Research, Enterprise, and Consumer Tools" title="Direct link to Agentic AI in Research, Enterprise, and Consumer Tools" translate="no">​</a></h2>
<p>Agentic AI systems differ from traditional AI tools in one crucial way: they are <strong>goal-directed and action-oriented</strong>. Instead of producing a single output and stopping, an agent observes its environment, decides what to do next, takes action, evaluates results, and iterates. This loop—often called <em>sense–think–act</em>—is what enables agents to function in complex, changing contexts.</p>
<p>Historically, early AI systems were either rule-based (explicit if–then logic) or narrow machine learning models trained for specific tasks. The emergence of large language models (LLMs), reinforcement learning, and tool-invocation frameworks made it possible to build agents that can reason in natural language, plan multi-step tasks, and interact with software systems. As a result, agentic AI began to appear simultaneously in research labs, enterprises, and consumer products.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="agentic-ai-in-research-environments">Agentic AI in Research Environments<a href="#agentic-ai-in-research-environments" class="hash-link" aria-label="Direct link to Agentic AI in Research Environments" title="Direct link to Agentic AI in Research Environments" translate="no">​</a></h3>
<p>In research settings, agentic AI often acts as an <strong>intellectual collaborator</strong>. These agents assist scientists and engineers by automating repetitive cognitive tasks, exploring hypotheses, and coordinating experiments.</p>
<p>Common research applications include:</p>
<ul>
<li class="">Literature review agents that continuously scan new publications and summarize findings</li>
<li class="">Experimental design agents that propose hypotheses and parameter sweeps</li>
<li class="">Simulation agents that run thousands of scenarios to explore design spaces</li>
</ul>
<p>For example, in materials science, agents are used to autonomously propose new material compositions, simulate their properties, and refine proposals based on results. The agent behaves much like a junior researcher: it does not “understand” chemistry in a human sense, but it can iteratively search a vast space faster than any person.</p>
<p>Why this matters is scale and speed. Research domains are increasingly data-rich and computationally intensive. Agentic AI helps researchers move from <em>manual exploration</em> to <em>continuous discovery</em>. However, these systems still require careful oversight, because they can confidently pursue flawed assumptions if initial goals are poorly defined.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="agentic-ai-in-enterprise-systems">Agentic AI in Enterprise Systems<a href="#agentic-ai-in-enterprise-systems" class="hash-link" aria-label="Direct link to Agentic AI in Enterprise Systems" title="Direct link to Agentic AI in Enterprise Systems" translate="no">​</a></h3>
<p>In enterprise contexts, agentic AI is often embedded in <strong>workflow automation and decision support</strong>. Unlike traditional automation, which follows rigid scripts, agents can adapt to exceptions, negotiate trade-offs, and coordinate across systems.</p>
<p>Typical enterprise use cases include:</p>
<ul>
<li class="">Customer support agents that resolve tickets end-to-end</li>
<li class="">Supply chain agents that monitor inventory, forecast demand, and place orders</li>
<li class="">IT operations agents that detect incidents, diagnose root causes, and trigger fixes</li>
</ul>
<p>An enterprise agent may monitor dashboards, query databases, call APIs, and escalate to humans only when uncertainty or risk is high. This is particularly valuable in large organizations, where information is fragmented across tools and teams.</p>
<p>However, enterprise environments expose limitations quickly. Data may be inconsistent, APIs may fail, and organizational rules may conflict. An agent that works well in a demo can struggle in production without extensive guardrails and monitoring.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="agentic-ai-in-consumer-products">Agentic AI in Consumer Products<a href="#agentic-ai-in-consumer-products" class="hash-link" aria-label="Direct link to Agentic AI in Consumer Products" title="Direct link to Agentic AI in Consumer Products" translate="no">​</a></h3>
<p>For consumers, agentic AI often appears as <strong>personal assistants</strong>. These agents aim to reduce cognitive load by handling everyday tasks autonomously.</p>
<p>Examples include:</p>
<ul>
<li class="">Travel agents that plan trips, book flights, and handle changes</li>
<li class="">Financial agents that track spending and optimize budgets</li>
<li class="">Smart home agents that adapt lighting, temperature, and energy usage</li>
</ul>
<p>A useful analogy is a human assistant who understands your preferences and acts proactively. However, unlike a human assistant, today’s AI agents lack deep contextual awareness and emotional intelligence. They rely on probabilistic reasoning, which can lead to surprising or frustrating behaviors.</p>
<p>Despite these challenges, consumer agents are popular because even imperfect autonomy can save time. The key trade-off is convenience versus control: users must decide how much authority to delegate.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="comparing-agentic-ai-across-domains">Comparing Agentic AI Across Domains<a href="#comparing-agentic-ai-across-domains" class="hash-link" aria-label="Direct link to Comparing Agentic AI Across Domains" title="Direct link to Comparing Agentic AI Across Domains" translate="no">​</a></h3>
<p>The following table highlights how agentic AI differs across research, enterprise, and consumer settings:</p>
<table><thead><tr><th>Domain</th><th>Primary Goal</th><th>Environment Complexity</th><th>Risk Tolerance</th><th>Human Oversight</th></tr></thead><tbody><tr><td>Research</td><td>Accelerate discovery</td><td>High (open-ended)</td><td>Medium</td><td>High</td></tr><tr><td>Enterprise</td><td>Optimize operations</td><td>Very high (messy data)</td><td>Low</td><td>Medium</td></tr><tr><td>Consumer</td><td>Convenience and personalization</td><td>Medium</td><td>Very low</td><td>Low to medium</td></tr></tbody></table>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="high-level-agentic-ai-loop-conceptual-view">High-Level Agentic AI Loop (Conceptual View)<a href="#high-level-agentic-ai-loop-conceptual-view" class="hash-link" aria-label="Direct link to High-Level Agentic AI Loop (Conceptual View)" title="Direct link to High-Level Agentic AI Loop (Conceptual View)" translate="no">​</a></h3>
<!-- -->
<p>This loop underlies all agentic systems, regardless of domain. What differs is the environment, the cost of mistakes, and the degree of human supervision.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-studies-of-deployed-agentic-systems">Case Studies of Deployed Agentic Systems<a href="#case-studies-of-deployed-agentic-systems" class="hash-link" aria-label="Direct link to Case Studies of Deployed Agentic Systems" title="Direct link to Case Studies of Deployed Agentic Systems" translate="no">​</a></h2>
<p>To move beyond abstract descriptions, it is essential to examine <strong>real deployed systems</strong>. Case studies reveal not only technical design choices, but also organizational pressures, user reactions, and unexpected failure modes.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-study-autonomous-research-agent-in-drug-discovery">Case Study: Autonomous Research Agent in Drug Discovery<a href="#case-study-autonomous-research-agent-in-drug-discovery" class="hash-link" aria-label="Direct link to Case Study: Autonomous Research Agent in Drug Discovery" title="Direct link to Case Study: Autonomous Research Agent in Drug Discovery" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="context">Context<a href="#context" class="hash-link" aria-label="Direct link to Context" title="Direct link to Context" translate="no">​</a></h3>
<p>In the early 2020s, pharmaceutical companies faced mounting pressure to reduce the time and cost required to develop new drugs. Traditional drug discovery is slow, often taking over a decade from initial hypothesis to approved medication. A mid-sized biotech company partnered with an AI research lab to deploy an <strong>autonomous research agent</strong> to accelerate early-stage drug discovery.</p>
<p>The agent was designed to operate in a highly complex scientific environment. It had access to molecular databases, simulation tools, and internal experimental results. Importantly, it was not meant to replace scientists, but to act as a tireless collaborator that could explore ideas continuously.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="problem">Problem<a href="#problem" class="hash-link" aria-label="Direct link to Problem" title="Direct link to Problem" translate="no">​</a></h3>
<p>The central problem was <strong>search complexity</strong>. The number of possible molecular structures is astronomically large, far beyond what human teams can explore manually. Traditional computational pipelines required experts to specify each step, creating bottlenecks.</p>
<p>Additionally, human researchers struggled with cognitive bias. They tended to explore familiar molecular families, overlooking unconventional but promising candidates. The company needed a system that could explore broadly, learn from results, and adjust strategies dynamically.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="solution">Solution<a href="#solution" class="hash-link" aria-label="Direct link to Solution" title="Direct link to Solution" translate="no">​</a></h3>
<p>The solution was an agentic system built around a planning-and-feedback loop. The agent:</p>
<ol>
<li class="">Generated hypotheses about promising molecular structures</li>
<li class="">Ran simulations to predict binding affinity and toxicity</li>
<li class="">Ranked candidates based on multiple objectives</li>
<li class="">Proposed laboratory experiments for validation</li>
<li class="">Incorporated experimental feedback into future plans</li>
</ol>
<p>Crucially, the agent was constrained by <strong>scientist-defined guardrails</strong>. It could not schedule experiments without approval, and its reasoning traces were logged for review. This hybrid approach balanced autonomy with safety.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results" translate="no">​</a></h3>
<p>Within six months, the agent identified several novel candidate molecules that human teams had not considered. Simulation throughput increased dramatically, and researchers reported spending more time on interpretation rather than setup.</p>
<p>However, limitations were evident. The agent sometimes optimized for simulation metrics that did not translate well to real-world lab results. Latency between experiments slowed learning loops, and scientists had to intervene frequently to adjust objectives.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="lessons-learned">Lessons Learned<a href="#lessons-learned" class="hash-link" aria-label="Direct link to Lessons Learned" title="Direct link to Lessons Learned" translate="no">​</a></h3>
<p>The key lesson was that <strong>agentic AI excels at exploration, not judgment</strong>. When paired with human expertise, it expanded the search space and surfaced new ideas. When left unchecked, it could pursue misleading objectives.</p>
<p>This case illustrates a broader principle: agentic systems are most effective when designed as <em>partners</em>, not replacements.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="technical-limitations-reliability-and-latency">Technical Limitations: Reliability and Latency<a href="#technical-limitations-reliability-and-latency" class="hash-link" aria-label="Direct link to Technical Limitations: Reliability and Latency" title="Direct link to Technical Limitations: Reliability and Latency" translate="no">​</a></h2>
<p>Despite impressive demonstrations, today’s agentic AI systems face fundamental technical constraints. Two of the most significant are <strong>reliability</strong> and <strong>latency</strong>. These limitations arise not from poor engineering alone, but from the probabilistic nature of modern AI models and the complexity of real-world environments.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="reliability-consistency-and-correctness">Reliability: Consistency and Correctness<a href="#reliability-consistency-and-correctness" class="hash-link" aria-label="Direct link to Reliability: Consistency and Correctness" title="Direct link to Reliability: Consistency and Correctness" translate="no">​</a></h3>
<p>Reliability refers to an agent’s ability to behave consistently and correctly across situations. Unlike traditional software, agentic AI systems often rely on stochastic models. This means the same input can produce different outputs at different times.</p>
<p>Several factors undermine reliability:</p>
<ul>
<li class=""><strong>Model uncertainty</strong>: LLMs generate plausible responses, not guaranteed truths</li>
<li class=""><strong>Tool failures</strong>: APIs, databases, or external systems may be unavailable</li>
<li class=""><strong>Goal misinterpretation</strong>: Ambiguous objectives can lead to unintended actions</li>
</ul>
<p>An analogy is a highly capable intern who sometimes misunderstands instructions but speaks confidently. Without supervision, mistakes can propagate quickly.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="latency-time-to-action">Latency: Time-to-Action<a href="#latency-time-to-action" class="hash-link" aria-label="Direct link to Latency: Time-to-Action" title="Direct link to Latency: Time-to-Action" translate="no">​</a></h3>
<p>Latency is the delay between observation and action. In agentic systems, latency accumulates across multiple steps:</p>
<ol>
<li class="">Interpreting input</li>
<li class="">Reasoning and planning</li>
<li class="">Calling tools or APIs</li>
<li class="">Waiting for responses</li>
</ol>
<p>In consumer tools, latency affects user experience. In enterprise or safety-critical systems, it can make agents unusable. For example, an incident-response agent that takes minutes to diagnose a problem may be worse than a human operator.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="trade-offs-between-reliability-and-speed">Trade-offs Between Reliability and Speed<a href="#trade-offs-between-reliability-and-speed" class="hash-link" aria-label="Direct link to Trade-offs Between Reliability and Speed" title="Direct link to Trade-offs Between Reliability and Speed" translate="no">​</a></h3>
<p>Improving reliability often increases latency. Adding verification steps, human approval, or redundant checks slows the system. Conversely, optimizing for speed may reduce safeguards.</p>
<table><thead><tr><th>Design Choice</th><th>Improves Reliability</th><th>Increases Latency</th></tr></thead><tbody><tr><td>Human-in-the-loop</td><td>Yes</td><td>Yes</td></tr><tr><td>Multiple model consensus</td><td>Yes</td><td>Yes</td></tr><tr><td>Single fast model</td><td>No</td><td>No</td></tr></tbody></table>
<p>Designers must choose trade-offs based on context and risk tolerance.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="reliability-control-flow-simplified">Reliability Control Flow (Simplified)<a href="#reliability-control-flow-simplified" class="hash-link" aria-label="Direct link to Reliability Control Flow (Simplified)" title="Direct link to Reliability Control Flow (Simplified)" translate="no">​</a></h3>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="operational-risks-and-maintenance-challenges">Operational Risks and Maintenance Challenges<a href="#operational-risks-and-maintenance-challenges" class="hash-link" aria-label="Direct link to Operational Risks and Maintenance Challenges" title="Direct link to Operational Risks and Maintenance Challenges" translate="no">​</a></h2>
<p>Deploying agentic AI in the real world introduces operational challenges that go far beyond model accuracy. These systems are <strong>living systems</strong>: they interact with changing environments, evolving data, and human organizations.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="continuous-monitoring-and-drift">Continuous Monitoring and Drift<a href="#continuous-monitoring-and-drift" class="hash-link" aria-label="Direct link to Continuous Monitoring and Drift" title="Direct link to Continuous Monitoring and Drift" translate="no">​</a></h3>
<p>One major risk is <strong>behavioral drift</strong>. As environments change, an agent’s learned strategies may become suboptimal or dangerous. For example, a pricing agent trained on historical data may behave poorly during market shocks.</p>
<p>Operational teams must monitor:</p>
<ul>
<li class="">Action distributions over time</li>
<li class="">Failure rates and near-misses</li>
<li class="">Alignment with business or ethical goals</li>
</ul>
<p>This requires infrastructure, not just models.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="maintenance-and-cost">Maintenance and Cost<a href="#maintenance-and-cost" class="hash-link" aria-label="Direct link to Maintenance and Cost" title="Direct link to Maintenance and Cost" translate="no">​</a></h3>
<p>Agentic systems are expensive to maintain. They often rely on multiple models, external tools, and orchestration layers. Each component can fail independently.</p>
<p>Costs include:</p>
<ul>
<li class="">Compute and API usage</li>
<li class="">Human oversight and review</li>
<li class="">Updating prompts, rules, and constraints</li>
</ul>
<p>Without careful design, maintenance costs can outweigh benefits.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="security-and-abuse-risks">Security and Abuse Risks<a href="#security-and-abuse-risks" class="hash-link" aria-label="Direct link to Security and Abuse Risks" title="Direct link to Security and Abuse Risks" translate="no">​</a></h3>
<p>Agents with action capabilities can be abused. A compromised agent might leak data, execute harmful actions, or be manipulated via prompt injection. This makes security a central operational concern.</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="agent-lifecycle-in-production">Agent Lifecycle in Production<a href="#agent-lifecycle-in-production" class="hash-link" aria-label="Direct link to Agent Lifecycle in Production" title="Direct link to Agent Lifecycle in Production" translate="no">​</a></h3>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="human-trust-and-usability-concerns">Human Trust and Usability Concerns<a href="#human-trust-and-usability-concerns" class="hash-link" aria-label="Direct link to Human Trust and Usability Concerns" title="Direct link to Human Trust and Usability Concerns" translate="no">​</a></h2>
<p>Even if an agent works technically, it must be <strong>trusted and usable</strong> by humans. Trust is not automatic; it emerges from consistent, transparent, and understandable behavior.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-trust-gap">The Trust Gap<a href="#the-trust-gap" class="hash-link" aria-label="Direct link to The Trust Gap" title="Direct link to The Trust Gap" translate="no">​</a></h3>
<p>Users often either over-trust or under-trust agents. Over-trust leads to complacency, while under-trust negates benefits. This is known as the <em>automation trust gap</em>.</p>
<p>Factors influencing trust include:</p>
<ul>
<li class="">Explainability of actions</li>
<li class="">Predictability of behavior</li>
<li class="">Ease of intervention</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="usability-and-cognitive-load">Usability and Cognitive Load<a href="#usability-and-cognitive-load" class="hash-link" aria-label="Direct link to Usability and Cognitive Load" title="Direct link to Usability and Cognitive Load" translate="no">​</a></h3>
<p>Ironically, poorly designed agents can increase cognitive load. Users may spend more time supervising than doing the task themselves. Clear interfaces, meaningful summaries, and simple controls are essential.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ethical-and-emotional-dimensions">Ethical and Emotional Dimensions<a href="#ethical-and-emotional-dimensions" class="hash-link" aria-label="Direct link to Ethical and Emotional Dimensions" title="Direct link to Ethical and Emotional Dimensions" translate="no">​</a></h3>
<p>Humans attribute intent and personality to agents. This can lead to emotional attachment or misplaced responsibility. Designers must be careful not to mislead users about an agent’s capabilities or understanding.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="future-directions-and-open-research-problems">Future Directions and Open Research Problems<a href="#future-directions-and-open-research-problems" class="hash-link" aria-label="Direct link to Future Directions and Open Research Problems" title="Direct link to Future Directions and Open Research Problems" translate="no">​</a></h2>
<p>Agentic AI is still in its early stages. Many open research problems remain, spanning technical, social, and philosophical dimensions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="toward-more-reliable-agents">Toward More Reliable Agents<a href="#toward-more-reliable-agents" class="hash-link" aria-label="Direct link to Toward More Reliable Agents" title="Direct link to Toward More Reliable Agents" translate="no">​</a></h3>
<p>Future research focuses on:</p>
<ul>
<li class="">Formal verification of agent behavior</li>
<li class="">Hybrid symbolic–neural reasoning</li>
<li class="">Better uncertainty estimation</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="scaling-autonomy-safely">Scaling Autonomy Safely<a href="#scaling-autonomy-safely" class="hash-link" aria-label="Direct link to Scaling Autonomy Safely" title="Direct link to Scaling Autonomy Safely" translate="no">​</a></h3>
<p>As agents gain more autonomy, governance becomes critical. How do we set boundaries? Who is accountable when things go wrong?</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="humanagent-collaboration">Human–Agent Collaboration<a href="#humanagent-collaboration" class="hash-link" aria-label="Direct link to Human–Agent Collaboration" title="Direct link to Human–Agent Collaboration" translate="no">​</a></h3>
<p>The most promising direction is <strong>co-adaptation</strong>: systems that learn not only about tasks, but about human preferences, trust levels, and feedback styles.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>Agentic AI represents a significant shift from passive tools to active, goal-directed systems. Today, these agents are already deployed in research, enterprise, and consumer contexts, delivering real value while exposing serious limitations. Through detailed case studies, we saw how autonomy can accelerate discovery—but also how reliability, latency, and operational complexity constrain real-world use.</p>
<p>Crucially, agentic AI is not just a technical challenge. It is a socio-technical system that must balance autonomy with oversight, efficiency with safety, and convenience with trust. Understanding these trade-offs is essential for anyone designing, deploying, or using agentic systems.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="reflection-questions">Reflection Questions<a href="#reflection-questions" class="hash-link" aria-label="Direct link to Reflection Questions" title="Direct link to Reflection Questions" translate="no">​</a></h2>
<ol>
<li class="">In which domains do you think agentic AI provides the most immediate value, and why?</li>
<li class="">How should designers balance autonomy and human oversight in high-risk environments?</li>
<li class="">What factors most influence your personal trust in an autonomous system?</li>
<li class="">Which current limitations do you think are primarily technical, and which are social or organizational?</li>
<li class="">How might agentic AI change the nature of human work over the next decade?</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/module-1-introduction-agentic-ai/chapter-3"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Agentic AI vs Traditional AI and LLM Applications</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/module-2-core-components/chapter-1"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">The Agent Loop: Observe, Think, Act</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#agentic-ai-in-research-enterprise-and-consumer-tools" class="table-of-contents__link toc-highlight">Agentic AI in Research, Enterprise, and Consumer Tools</a><ul><li><a href="#agentic-ai-in-research-environments" class="table-of-contents__link toc-highlight">Agentic AI in Research Environments</a></li><li><a href="#agentic-ai-in-enterprise-systems" class="table-of-contents__link toc-highlight">Agentic AI in Enterprise Systems</a></li><li><a href="#agentic-ai-in-consumer-products" class="table-of-contents__link toc-highlight">Agentic AI in Consumer Products</a></li><li><a href="#comparing-agentic-ai-across-domains" class="table-of-contents__link toc-highlight">Comparing Agentic AI Across Domains</a></li><li><a href="#high-level-agentic-ai-loop-conceptual-view" class="table-of-contents__link toc-highlight">High-Level Agentic AI Loop (Conceptual View)</a></li></ul></li><li><a href="#case-studies-of-deployed-agentic-systems" class="table-of-contents__link toc-highlight">Case Studies of Deployed Agentic Systems</a></li><li><a href="#case-study-autonomous-research-agent-in-drug-discovery" class="table-of-contents__link toc-highlight">Case Study: Autonomous Research Agent in Drug Discovery</a><ul><li><a href="#context" class="table-of-contents__link toc-highlight">Context</a></li><li><a href="#problem" class="table-of-contents__link toc-highlight">Problem</a></li><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#lessons-learned" class="table-of-contents__link toc-highlight">Lessons Learned</a></li></ul></li><li><a href="#technical-limitations-reliability-and-latency" class="table-of-contents__link toc-highlight">Technical Limitations: Reliability and Latency</a><ul><li><a href="#reliability-consistency-and-correctness" class="table-of-contents__link toc-highlight">Reliability: Consistency and Correctness</a></li><li><a href="#latency-time-to-action" class="table-of-contents__link toc-highlight">Latency: Time-to-Action</a></li><li><a href="#trade-offs-between-reliability-and-speed" class="table-of-contents__link toc-highlight">Trade-offs Between Reliability and Speed</a></li><li><a href="#reliability-control-flow-simplified" class="table-of-contents__link toc-highlight">Reliability Control Flow (Simplified)</a></li></ul></li><li><a href="#operational-risks-and-maintenance-challenges" class="table-of-contents__link toc-highlight">Operational Risks and Maintenance Challenges</a><ul><li><a href="#continuous-monitoring-and-drift" class="table-of-contents__link toc-highlight">Continuous Monitoring and Drift</a></li><li><a href="#maintenance-and-cost" class="table-of-contents__link toc-highlight">Maintenance and Cost</a></li><li><a href="#security-and-abuse-risks" class="table-of-contents__link toc-highlight">Security and Abuse Risks</a></li><li><a href="#agent-lifecycle-in-production" class="table-of-contents__link toc-highlight">Agent Lifecycle in Production</a></li></ul></li><li><a href="#human-trust-and-usability-concerns" class="table-of-contents__link toc-highlight">Human Trust and Usability Concerns</a><ul><li><a href="#the-trust-gap" class="table-of-contents__link toc-highlight">The Trust Gap</a></li><li><a href="#usability-and-cognitive-load" class="table-of-contents__link toc-highlight">Usability and Cognitive Load</a></li><li><a href="#ethical-and-emotional-dimensions" class="table-of-contents__link toc-highlight">Ethical and Emotional Dimensions</a></li></ul></li><li><a href="#future-directions-and-open-research-problems" class="table-of-contents__link toc-highlight">Future Directions and Open Research Problems</a><ul><li><a href="#toward-more-reliable-agents" class="table-of-contents__link toc-highlight">Toward More Reliable Agents</a></li><li><a href="#scaling-autonomy-safely" class="table-of-contents__link toc-highlight">Scaling Autonomy Safely</a></li><li><a href="#humanagent-collaboration" class="table-of-contents__link toc-highlight">Human–Agent Collaboration</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#reflection-questions" class="table-of-contents__link toc-highlight">Reflection Questions</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Learning Materials. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>