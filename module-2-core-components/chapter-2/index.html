<!doctype html>
<html lang="id" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-2-core-components/chapter-2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Prompting as Control Logic | Learning Materials</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://localhost:3000/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="http://localhost:3000/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="http://localhost:3000/module-2-core-components/chapter-2"><meta data-rh="true" property="og:locale" content="id"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="id"><meta data-rh="true" name="docsearch:language" content="id"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Prompting as Control Logic | Learning Materials"><meta data-rh="true" name="description" content="Learning Objectives"><meta data-rh="true" property="og:description" content="Learning Objectives"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="http://localhost:3000/module-2-core-components/chapter-2"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-2-core-components/chapter-2" hreflang="id"><link data-rh="true" rel="alternate" href="http://localhost:3000/en/module-2-core-components/chapter-2" hreflang="en"><link data-rh="true" rel="alternate" href="http://localhost:3000/module-2-core-components/chapter-2" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Prompting as Control Logic","item":"http://localhost:3000/module-2-core-components/chapter-2"}]}</script><link rel="stylesheet" href="/assets/css/styles.b3bb77c0.css">
<script src="/assets/js/runtime~main.ea5f7858.js" defer="defer"></script>
<script src="/assets/js/main.e790a99d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Lewati ke konten utama"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Lewati ke konten utama</a></div><nav aria-label="Utama" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alihkan bilah sisi" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Learning Materials Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Learning Materials</b></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Bahasa Indonesia</a><ul class="dropdown__menu"><li><a href="/module-2-core-components/chapter-2" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="id">Bahasa Indonesia</a></li><li><a href="/en/module-2-core-components/chapter-2" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Ubah antara modus gelap dan modus terang (saat ini system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Gulir kembali ke atas" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Bilah sisi dokumentasi" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/"><span title="Deep Dive into Agentic AI: Design, Implementation, and Production Systems" class="linkLabel_WmDU">Deep Dive into Agentic AI: Design, Implementation, and Production Systems</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-1-introduction-agentic-ai/chapter-1"><span title="Introduction to Agentic AI and Autonomous Systems" class="categoryLinkLabel_W154">Introduction to Agentic AI and Autonomous Systems</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/module-2-core-components/chapter-1"><span title="Core Components of an AI Agent" class="categoryLinkLabel_W154">Core Components of an AI Agent</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/module-2-core-components/chapter-1"><span title="The Agent Loop: Observe, Think, Act" class="linkLabel_WmDU">The Agent Loop: Observe, Think, Act</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/module-2-core-components/chapter-2"><span title="Prompting as Control Logic" class="linkLabel_WmDU">Prompting as Control Logic</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/module-2-core-components/chapter-3"><span title="Memory Systems: Short-Term and Long-Term" class="linkLabel_WmDU">Memory Systems: Short-Term and Long-Term</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/module-2-core-components/chapter-4"><span title="Tools, APIs, and Environment Interaction" class="linkLabel_WmDU">Tools, APIs, and Environment Interaction</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-3-architectures-patterns/chapter-1"><span title="Agent Architectures and Design Patterns" class="categoryLinkLabel_W154">Agent Architectures and Design Patterns</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-4-agent-frameworks/chapter-1"><span title="Building Agents with Modern Frameworks" class="categoryLinkLabel_W154">Building Agents with Modern Frameworks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-5-planning-memory-decision/chapter-1"><span title="Planning, Memory, and Decision-Making" class="categoryLinkLabel_W154">Planning, Memory, and Decision-Making</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-6-multi-agent/chapter-1"><span title="Multi-Agent Systems and Collaboration" class="categoryLinkLabel_W154">Multi-Agent Systems and Collaboration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-7-evaluation-safety/chapter-1"><span title="Evaluation, Safety, and Alignment" class="categoryLinkLabel_W154">Evaluation, Safety, and Alignment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-8-scaling-production/chapter-1"><span title="Scaling, Optimization, and Production Deployment" class="categoryLinkLabel_W154">Scaling, Optimization, and Production Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/module-9-capstone/chapter-1"><span title="Capstone Project: Build an End-to-End Agentic AI System" class="categoryLinkLabel_W154">Capstone Project: Build an End-to-End Agentic AI System</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Runut navigasi"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Halaman utama" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Core Components of an AI Agent</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Prompting as Control Logic</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">Pada halaman ini</button></div><div class="theme-doc-markdown markdown"><header><h1>Core Components of an AI Agent: Prompting as Control Logic</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Taut langsung ke Learning Objectives" title="Taut langsung ke Learning Objectives" translate="no">​</a></h2>
<ul>
<li class="">Explain how prompts function as control logic</li>
<li class="">Design structured prompts for agent reasoning</li>
<li class="">Differentiate prompt types and their roles</li>
<li class="">Apply prompt chaining to complex tasks</li>
<li class="">Evaluate prompt quality using defined criteria</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Taut langsung ke Introduction" title="Taut langsung ke Introduction" translate="no">​</a></h2>
<p>This chapter explores how prompts act as the primary control mechanism for LLM-based agents, shaping reasoning and behavior.</p>
<hr>
<hr>
<p>When people first encounter large language models (LLMs), prompts often look deceptively simple—just text instructions typed into a box. However, as LLM-based systems have evolved from single-turn chatbots into autonomous or semi-autonomous agents, prompts have taken on a much deeper and more powerful role. In modern AI agents, prompts are not merely inputs; they act as <em>control logic</em>, shaping how the agent reasons, plans, reacts to errors, and interacts with tools and users.</p>
<p>This chapter explores a central idea: <strong>prompts function as implicit programs</strong> that govern the behavior of LLM-based agents. Unlike traditional software, where control flow is expressed through explicit code constructs like loops and conditionals, LLM agents rely on carefully designed prompt structures to guide reasoning, decision-making, and action. Understanding prompting as control logic is essential for anyone designing agents that must operate reliably, transparently, and safely in real-world environments.</p>
<p>We will start with foundational concepts—what it means to think of prompts as programs—then gradually move toward more advanced techniques such as structured prompting, prompt chaining, failure handling, and evaluation. Throughout the chapter, you will find detailed explanations, real-world analogies, practical examples, visual diagrams, and a comprehensive case study that ties these ideas together. By the end, you should be able to design, analyze, and evaluate prompts not as ad-hoc instructions, but as first-class components of an intelligent system.</p>
<hr>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li class="">Explain how prompts function as control logic in LLM-based agents</li>
<li class="">Describe prompts as implicit programs and reason about their structure</li>
<li class="">Differentiate between system prompts, instruction prompts, and their roles</li>
<li class="">Design structured prompts and reusable templates for agent reasoning</li>
<li class="">Apply prompt chaining and task decomposition to complex problems</li>
<li class="">Handle failures and uncertainty through robust prompt design</li>
<li class="">Evaluate prompt effectiveness using clear, practical criteria</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prompts-as-implicit-programs">Prompts as Implicit Programs<a href="#prompts-as-implicit-programs" class="hash-link" aria-label="Taut langsung ke Prompts as Implicit Programs" title="Taut langsung ke Prompts as Implicit Programs" translate="no">​</a></h2>
<p>Prompts are often described casually as “instructions,” but this description understates their importance in agent-based systems. In practice, a prompt operates much like a <em>program</em>: it defines goals, constraints, allowable actions, and reasoning strategies. The key difference is that this program is written in natural language rather than a formal programming syntax.</p>
<p>Historically, this idea emerged as practitioners noticed consistent patterns in model behavior. Early users of LLMs found that small changes in wording could drastically alter outputs. Over time, these observations led to the realization that prompts encode <em>control flow</em>. For example, telling a model to “think step by step” introduces a reasoning loop, while instructing it to “verify your answer before responding” introduces a form of self-checking logic. These are not just stylistic preferences—they are computational controls.</p>
<p>From a conceptual standpoint, prompts as implicit programs work because LLMs are trained to predict text conditioned on context. When you include instructions, examples, constraints, and formatting rules, you are shaping the probability space in which the model operates. The prompt becomes a <em>soft program</em>:</p>
<ul>
<li class="">The <strong>goal</strong> is defined by the task description</li>
<li class="">The <strong>constraints</strong> are expressed as rules (“do not hallucinate sources”)</li>
<li class="">The <strong>control flow</strong> is suggested through ordered steps or reasoning cues</li>
<li class="">The <strong>output format</strong> acts like a type signature</li>
</ul>
<p>An analogy can help here. Imagine a highly skilled human assistant who follows instructions extremely literally but has no memory beyond what you tell them. The quality of their work depends almost entirely on how clearly you describe:</p>
<ul>
<li class="">What they should do</li>
<li class="">How they should think</li>
<li class="">What they should avoid</li>
<li class="">How they should present results</li>
</ul>
<p>In this sense, prompting resembles writing a detailed job manual rather than giving a casual request.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-a-prompt-as-a-program">Example: A Prompt as a Program<a href="#example-a-prompt-as-a-program" class="hash-link" aria-label="Taut langsung ke Example: A Prompt as a Program" title="Taut langsung ke Example: A Prompt as a Program" translate="no">​</a></h3>
<p>Consider the difference between these two prompts:</p>
<ul>
<li class=""><em>“Summarize this document.”</em></li>
<li class=""><em>“Summarize this document in three bullet points, focusing on risks and assumptions. If information is missing, explicitly state what is unknown.”</em></li>
</ul>
<p>The second prompt embeds:</p>
<ul>
<li class="">A formatting rule (three bullet points)</li>
<li class="">A prioritization strategy (risks and assumptions)</li>
<li class="">A failure-handling policy (explicitly state unknowns)</li>
</ul>
<p>That is already a small program.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-this-matters-for-agents">Why This Matters for Agents<a href="#why-this-matters-for-agents" class="hash-link" aria-label="Taut langsung ke Why This Matters for Agents" title="Taut langsung ke Why This Matters for Agents" translate="no">​</a></h3>
<p>In agentic systems, prompts often replace traditional control structures:</p>
<ul>
<li class="">Instead of <code>if/else</code>, we use conditional language (“If the user intent is unclear, ask a clarifying question.”)</li>
<li class="">Instead of loops, we use iterative reasoning (“Repeat until the answer is consistent.”)</li>
<li class="">Instead of exceptions, we use fallback instructions (“If you cannot complete the task, explain why.”)</li>
</ul>
<p>The implication is profound: <strong>prompt design becomes a form of software engineering</strong>. Poorly designed prompts lead to brittle agents, while well-designed prompts lead to robust, adaptable behavior.</p>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="instruction-prompts-vs-system-prompts">Instruction Prompts vs System Prompts<a href="#instruction-prompts-vs-system-prompts" class="hash-link" aria-label="Taut langsung ke Instruction Prompts vs System Prompts" title="Taut langsung ke Instruction Prompts vs System Prompts" translate="no">​</a></h2>
<p>As LLM platforms matured, prompt design became more structured. One key development was the separation between <strong>system prompts</strong> and <strong>instruction prompts</strong>. Understanding their differences is crucial for controlling agent behavior reliably.</p>
<p>System prompts define the <em>identity, role, and global behavior</em> of the agent. They are typically set once at the beginning of a session and remain constant. Instruction prompts, on the other hand, define <em>what the agent should do right now</em>—they are task-specific and change frequently.</p>
<p>Historically, this separation mirrors concepts from operating systems. The system prompt is like the operating system kernel: it defines core rules and capabilities. Instruction prompts are like user-level applications: they request specific tasks within those rules.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="system-prompts-the-agents-constitution">System Prompts: The Agent’s Constitution<a href="#system-prompts-the-agents-constitution" class="hash-link" aria-label="Taut langsung ke System Prompts: The Agent’s Constitution" title="Taut langsung ke System Prompts: The Agent’s Constitution" translate="no">​</a></h3>
<p>System prompts answer questions such as:</p>
<ul>
<li class="">Who are you?</li>
<li class="">What is your role?</li>
<li class="">What rules must you always follow?</li>
</ul>
<p>They are especially important for:</p>
<ul>
<li class="">Safety constraints</li>
<li class="">Tone and communication style</li>
<li class="">Tool usage policies</li>
</ul>
<p>For example, a system prompt might state that the agent is a “careful financial analyst” who must avoid speculation and clearly label assumptions. This instruction influences <em>every response</em>, even when not explicitly referenced.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="instruction-prompts-task-level-control">Instruction Prompts: Task-Level Control<a href="#instruction-prompts-task-level-control" class="hash-link" aria-label="Taut langsung ke Instruction Prompts: Task-Level Control" title="Taut langsung ke Instruction Prompts: Task-Level Control" translate="no">​</a></h3>
<p>Instruction prompts are more tactical. They specify:</p>
<ul>
<li class="">The immediate task</li>
<li class="">The required output format</li>
<li class="">Any task-specific constraints</li>
</ul>
<p>These prompts often include examples, step-by-step instructions, or domain context. Unlike system prompts, instruction prompts are expected to change frequently as the agent handles different tasks.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="comparison-table">Comparison Table<a href="#comparison-table" class="hash-link" aria-label="Taut langsung ke Comparison Table" title="Taut langsung ke Comparison Table" translate="no">​</a></h3>
<table><thead><tr><th>Aspect</th><th>System Prompt</th><th>Instruction Prompt</th></tr></thead><tbody><tr><td>Scope</td><td>Global, persistent</td><td>Local, task-specific</td></tr><tr><td>Purpose</td><td>Define identity and rules</td><td>Define what to do now</td></tr><tr><td>Frequency of change</td><td>Rare</td><td>Frequent</td></tr><tr><td>Safety impact</td><td>High</td><td>Medium</td></tr><tr><td>Example</td><td>“You are a medical assistant…”</td><td>“Summarize this patient note…”</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-implications">Practical Implications<a href="#practical-implications" class="hash-link" aria-label="Taut langsung ke Practical Implications" title="Taut langsung ke Practical Implications" translate="no">​</a></h3>
<p>Confusing these roles leads to unstable agents. If safety rules are placed in instruction prompts, they may be forgotten or overridden. Conversely, if task details are placed in system prompts, flexibility is lost.</p>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="structured-prompting-and-templates">Structured Prompting and Templates<a href="#structured-prompting-and-templates" class="hash-link" aria-label="Taut langsung ke Structured Prompting and Templates" title="Taut langsung ke Structured Prompting and Templates" translate="no">​</a></h2>
<p>As agent complexity increases, ad-hoc prompts become unmanageable. Structured prompting emerged as a response to this problem. Instead of writing free-form text each time, designers use <em>templates</em> with clearly defined sections, placeholders, and reasoning scaffolds.</p>
<p>Structured prompting borrows ideas from traditional programming and technical writing. Just as APIs enforce structure to reduce ambiguity, structured prompts reduce uncertainty for the model. They also make prompts reusable, testable, and easier to debug.</p>
<p>A typical structured prompt might include:</p>
<ul>
<li class="">Role definition</li>
<li class="">Task description</li>
<li class="">Inputs (clearly labeled)</li>
<li class="">Step-by-step reasoning instructions</li>
<li class="">Output schema</li>
</ul>
<p>This structure matters because LLMs are sensitive to context ordering and clarity. When information is clearly segmented, the model can allocate attention more effectively.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-template">Example Template<a href="#example-template" class="hash-link" aria-label="Taut langsung ke Example Template" title="Taut langsung ke Example Template" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Role: You are an expert legal analyst.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Task: Evaluate the contract clause below.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Criteria:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Identify risks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Suggest improvements</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Output Format:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Risk Summary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Suggested Revisions</span><br></span></code></pre></div></div>
<p>This template acts like a function signature in code.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="advantages-and-limitations">Advantages and Limitations<a href="#advantages-and-limitations" class="hash-link" aria-label="Taut langsung ke Advantages and Limitations" title="Taut langsung ke Advantages and Limitations" translate="no">​</a></h3>
<p><strong>Advantages</strong></p>
<ul>
<li class="">Consistency across tasks</li>
<li class="">Easier evaluation and debugging</li>
<li class="">Improved reasoning reliability</li>
</ul>
<p><strong>Limitations</strong></p>
<ul>
<li class="">Can become verbose</li>
<li class="">Over-structuring may reduce creativity</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-unstructured-vs-structured-prompting">Table: Unstructured vs Structured Prompting<a href="#table-unstructured-vs-structured-prompting" class="hash-link" aria-label="Taut langsung ke Table: Unstructured vs Structured Prompting" title="Taut langsung ke Table: Unstructured vs Structured Prompting" translate="no">​</a></h3>
<table><thead><tr><th>Dimension</th><th>Unstructured</th><th>Structured</th></tr></thead><tbody><tr><td>Flexibility</td><td>High</td><td>Medium</td></tr><tr><td>Reliability</td><td>Low</td><td>High</td></tr><tr><td>Reusability</td><td>Low</td><td>High</td></tr><tr><td>Debuggability</td><td>Low</td><td>High</td></tr></tbody></table>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prompt-chaining-and-decomposition">Prompt Chaining and Decomposition<a href="#prompt-chaining-and-decomposition" class="hash-link" aria-label="Taut langsung ke Prompt Chaining and Decomposition" title="Taut langsung ke Prompt Chaining and Decomposition" translate="no">​</a></h2>
<p>Prompt chaining is a technique where a complex task is broken into multiple smaller prompts, executed sequentially. Each prompt handles a subtask, and its output feeds into the next prompt. This mirrors <em>functional decomposition</em> in software engineering.</p>
<p>The need for prompt chaining arises because LLMs have limited context windows and may struggle with multi-step reasoning in a single pass. By decomposing tasks, we:</p>
<ul>
<li class="">Reduce cognitive load on the model</li>
<li class="">Improve interpretability</li>
<li class="">Isolate errors</li>
</ul>
<p>For example, instead of asking an agent to “analyze a market and produce a strategy,” we might chain:</p>
<ol>
<li class="">Market summarization</li>
<li class="">Risk identification</li>
<li class="">Strategy generation</li>
<li class="">Strategy critique</li>
</ol>
<p>Each step has a focused prompt.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-example">Practical Example<a href="#practical-example" class="hash-link" aria-label="Taut langsung ke Practical Example" title="Taut langsung ke Practical Example" translate="no">​</a></h3>
<p>In customer support automation:</p>
<ul>
<li class="">Prompt 1 classifies the issue</li>
<li class="">Prompt 2 retrieves relevant policy</li>
<li class="">Prompt 3 generates a response</li>
</ul>
<p>This modularity allows targeted improvements without rewriting the entire system.</p>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="failure-handling-through-prompt-design">Failure Handling through Prompt Design<a href="#failure-handling-through-prompt-design" class="hash-link" aria-label="Taut langsung ke Failure Handling through Prompt Design" title="Taut langsung ke Failure Handling through Prompt Design" translate="no">​</a></h2>
<p>No agent is perfect. Failures—hallucinations, ambiguity, incomplete data—are inevitable. Prompt design is the first line of defense. Rather than trying to eliminate failures entirely, good prompts <em>anticipate and manage</em> them.</p>
<p>Failure-aware prompts explicitly instruct the model on what to do when:</p>
<ul>
<li class="">Information is missing</li>
<li class="">Confidence is low</li>
<li class="">Instructions conflict</li>
</ul>
<p>For example, telling the model to “ask a clarifying question if uncertain” transforms uncertainty from a silent failure into an interactive loop.</p>
<p>Common failure-handling strategies include:</p>
<ul>
<li class="">Explicit uncertainty disclosure</li>
<li class="">Fallback behaviors</li>
<li class="">Self-checking instructions</li>
</ul>
<p>These strategies align with human professional norms: experts say “I don’t know” when appropriate.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-failure-types-and-prompt-strategies">Table: Failure Types and Prompt Strategies<a href="#table-failure-types-and-prompt-strategies" class="hash-link" aria-label="Taut langsung ke Table: Failure Types and Prompt Strategies" title="Taut langsung ke Table: Failure Types and Prompt Strategies" translate="no">​</a></h3>
<table><thead><tr><th>Failure Type</th><th>Prompt Strategy</th></tr></thead><tbody><tr><td>Hallucination</td><td>Require citations or say “unknown”</td></tr><tr><td>Ambiguity</td><td>Ask clarifying questions</td></tr><tr><td>Overconfidence</td><td>Add confidence calibration step</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluating-prompt-effectiveness">Evaluating Prompt Effectiveness<a href="#evaluating-prompt-effectiveness" class="hash-link" aria-label="Taut langsung ke Evaluating Prompt Effectiveness" title="Taut langsung ke Evaluating Prompt Effectiveness" translate="no">​</a></h2>
<p>Evaluating prompts is essential because prompts <em>are code</em>. Yet unlike traditional code, prompts lack compilers or unit tests by default. Evaluation therefore relies on systematic criteria and empirical testing.</p>
<p>Effective prompt evaluation considers:</p>
<ul>
<li class="">Task success rate</li>
<li class="">Consistency across runs</li>
<li class="">Robustness to edge cases</li>
<li class="">Interpretability of reasoning</li>
</ul>
<p>One useful approach is to treat prompts as hypotheses and test them against a suite of representative inputs. Small changes can then be compared empirically.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="evaluation-criteria-table">Evaluation Criteria Table<a href="#evaluation-criteria-table" class="hash-link" aria-label="Taut langsung ke Evaluation Criteria Table" title="Taut langsung ke Evaluation Criteria Table" translate="no">​</a></h3>
<table><thead><tr><th>Criterion</th><th>Description</th></tr></thead><tbody><tr><td>Accuracy</td><td>Correctness of output</td></tr><tr><td>Robustness</td><td>Performance on edge cases</td></tr><tr><td>Clarity</td><td>Ease of understanding outputs</td></tr><tr><td>Safety</td><td>Avoidance of harmful behavior</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="case-study-designing-a-prompt-controlled-research-agent">Case Study: Designing a Prompt-Controlled Research Agent<a href="#case-study-designing-a-prompt-controlled-research-agent" class="hash-link" aria-label="Taut langsung ke Case Study: Designing a Prompt-Controlled Research Agent" title="Taut langsung ke Case Study: Designing a Prompt-Controlled Research Agent" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="context">Context<a href="#context" class="hash-link" aria-label="Taut langsung ke Context" title="Taut langsung ke Context" translate="no">​</a></h3>
<p>In 2024, a mid-sized consulting firm sought to build an internal AI research agent to support analysts. The agent needed to summarize reports, identify risks, and flag missing data. Analysts complained that earlier chatbot tools produced confident but unreliable summaries.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="problem">Problem<a href="#problem" class="hash-link" aria-label="Taut langsung ke Problem" title="Taut langsung ke Problem" translate="no">​</a></h3>
<p>The core challenge was control. The model often hallucinated data and failed to disclose uncertainty. Analysts needed an agent that behaved like a cautious junior researcher, not a persuasive writer. Traditional fine-tuning was too costly and slow.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="solution">Solution<a href="#solution" class="hash-link" aria-label="Taut langsung ke Solution" title="Taut langsung ke Solution" translate="no">​</a></h3>
<p>The team redesigned the agent around prompt-based control logic. A strong system prompt defined the agent’s role and epistemic humility. Structured instruction templates enforced step-by-step analysis. Prompt chaining separated summarization from risk analysis. Failure-handling rules required explicit uncertainty statements.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="results">Results<a href="#results" class="hash-link" aria-label="Taut langsung ke Results" title="Taut langsung ke Results" translate="no">​</a></h3>
<p>Within weeks, analysts reported higher trust in outputs. Hallucinations dropped significantly, and reviews became faster. While the agent was sometimes slower, its transparency outweighed speed concerns.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="lessons-learned">Lessons Learned<a href="#lessons-learned" class="hash-link" aria-label="Taut langsung ke Lessons Learned" title="Taut langsung ke Lessons Learned" translate="no">​</a></h3>
<p>The team learned that prompts are not UI text—they are architecture. Investing in prompt design delivered system-level improvements without model retraining.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Taut langsung ke Summary" title="Taut langsung ke Summary" translate="no">​</a></h2>
<p>Prompts are the backbone of LLM-based agents. They act as implicit programs that define goals, constraints, reasoning strategies, and failure behaviors. By understanding different prompt types, structuring prompts carefully, chaining them for complex tasks, and evaluating them systematically, we can design agents that are robust, transparent, and trustworthy. Prompting is not an art alone—it is a disciplined form of control logic.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="reflection-questions">Reflection Questions<a href="#reflection-questions" class="hash-link" aria-label="Taut langsung ke Reflection Questions" title="Taut langsung ke Reflection Questions" translate="no">​</a></h2>
<ol>
<li class="">In what ways are prompts similar to and different from traditional code?</li>
<li class="">How would you redesign a brittle prompt you’ve used before using structured templates?</li>
<li class="">What failure modes are most dangerous in your domain, and how could prompts mitigate them?</li>
<li class="">How might prompt evaluation become more standardized in the future?</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Halaman dokumentasi"><a class="pagination-nav__link pagination-nav__link--prev" href="/module-2-core-components/chapter-1"><div class="pagination-nav__sublabel">Sebelum</div><div class="pagination-nav__label">The Agent Loop: Observe, Think, Act</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/module-2-core-components/chapter-3"><div class="pagination-nav__sublabel">Berikut</div><div class="pagination-nav__label">Memory Systems: Short-Term and Long-Term</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#prompts-as-implicit-programs" class="table-of-contents__link toc-highlight">Prompts as Implicit Programs</a><ul><li><a href="#example-a-prompt-as-a-program" class="table-of-contents__link toc-highlight">Example: A Prompt as a Program</a></li><li><a href="#why-this-matters-for-agents" class="table-of-contents__link toc-highlight">Why This Matters for Agents</a></li></ul></li><li><a href="#instruction-prompts-vs-system-prompts" class="table-of-contents__link toc-highlight">Instruction Prompts vs System Prompts</a><ul><li><a href="#system-prompts-the-agents-constitution" class="table-of-contents__link toc-highlight">System Prompts: The Agent’s Constitution</a></li><li><a href="#instruction-prompts-task-level-control" class="table-of-contents__link toc-highlight">Instruction Prompts: Task-Level Control</a></li><li><a href="#comparison-table" class="table-of-contents__link toc-highlight">Comparison Table</a></li><li><a href="#practical-implications" class="table-of-contents__link toc-highlight">Practical Implications</a></li></ul></li><li><a href="#structured-prompting-and-templates" class="table-of-contents__link toc-highlight">Structured Prompting and Templates</a><ul><li><a href="#example-template" class="table-of-contents__link toc-highlight">Example Template</a></li><li><a href="#advantages-and-limitations" class="table-of-contents__link toc-highlight">Advantages and Limitations</a></li><li><a href="#table-unstructured-vs-structured-prompting" class="table-of-contents__link toc-highlight">Table: Unstructured vs Structured Prompting</a></li></ul></li><li><a href="#prompt-chaining-and-decomposition" class="table-of-contents__link toc-highlight">Prompt Chaining and Decomposition</a><ul><li><a href="#practical-example" class="table-of-contents__link toc-highlight">Practical Example</a></li></ul></li><li><a href="#failure-handling-through-prompt-design" class="table-of-contents__link toc-highlight">Failure Handling through Prompt Design</a><ul><li><a href="#table-failure-types-and-prompt-strategies" class="table-of-contents__link toc-highlight">Table: Failure Types and Prompt Strategies</a></li></ul></li><li><a href="#evaluating-prompt-effectiveness" class="table-of-contents__link toc-highlight">Evaluating Prompt Effectiveness</a><ul><li><a href="#evaluation-criteria-table" class="table-of-contents__link toc-highlight">Evaluation Criteria Table</a></li></ul></li><li><a href="#case-study-designing-a-prompt-controlled-research-agent" class="table-of-contents__link toc-highlight">Case Study: Designing a Prompt-Controlled Research Agent</a><ul><li><a href="#context" class="table-of-contents__link toc-highlight">Context</a></li><li><a href="#problem" class="table-of-contents__link toc-highlight">Problem</a></li><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#lessons-learned" class="table-of-contents__link toc-highlight">Lessons Learned</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#reflection-questions" class="table-of-contents__link toc-highlight">Reflection Questions</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Learning Materials. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>